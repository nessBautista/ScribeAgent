{
  "access_type": "PRIVATE",
  "action_description": null,
  "action_name": null,
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SimplePlotlyBarChartComponent",
            "id": "SimplePlotlyBarChartComponent-zBz6K",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-qAI2U",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SimplePlotlyBarChartComponent-zBz6K{≈ìdataType≈ì:≈ìSimplePlotlyBarChartComponent≈ì,≈ìid≈ì:≈ìSimplePlotlyBarChartComponent-zBz6K≈ì,≈ìname≈ì:≈ìcomponent_as_tool≈ì,≈ìoutput_types≈ì:[≈ìTool≈ì]}-Agent-qAI2U{≈ìfieldName≈ì:≈ìtools≈ì,≈ìid≈ì:≈ìAgent-qAI2U≈ì,≈ìinputTypes≈ì:[≈ìTool≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "SimplePlotlyBarChartComponent-zBz6K",
        "sourceHandle": "{≈ìdataType≈ì:≈ìSimplePlotlyBarChartComponent≈ì,≈ìid≈ì:≈ìSimplePlotlyBarChartComponent-zBz6K≈ì,≈ìname≈ì:≈ìcomponent_as_tool≈ì,≈ìoutput_types≈ì:[≈ìTool≈ì]}",
        "target": "Agent-qAI2U",
        "targetHandle": "{≈ìfieldName≈ì:≈ìtools≈ì,≈ìid≈ì:≈ìAgent-qAI2U≈ì,≈ìinputTypes≈ì:[≈ìTool≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-8FDNi",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "CSVAgent-A8Fx7",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LanguageModelComponent-8FDNi{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-8FDNi≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}-CSVAgent-A8Fx7{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìCSVAgent-A8Fx7≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "LanguageModelComponent-8FDNi",
        "sourceHandle": "{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-8FDNi≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}",
        "target": "CSVAgent-A8Fx7",
        "targetHandle": "{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìCSVAgent-A8Fx7≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PythonREPLComponent",
            "id": "PythonREPLComponent-B3m0U",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-8jyTp",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-PythonREPLComponent-B3m0U{≈ìdataType≈ì:≈ìPythonREPLComponent≈ì,≈ìid≈ì:≈ìPythonREPLComponent-B3m0U≈ì,≈ìname≈ì:≈ìcomponent_as_tool≈ì,≈ìoutput_types≈ì:[≈ìTool≈ì]}-Agent-8jyTp{≈ìfieldName≈ì:≈ìtools≈ì,≈ìid≈ì:≈ìAgent-8jyTp≈ì,≈ìinputTypes≈ì:[≈ìTool≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "PythonREPLComponent-B3m0U",
        "sourceHandle": "{≈ìdataType≈ì:≈ìPythonREPLComponent≈ì,≈ìid≈ì:≈ìPythonREPLComponent-B3m0U≈ì,≈ìname≈ì:≈ìcomponent_as_tool≈ì,≈ìoutput_types≈ì:[≈ìTool≈ì]}",
        "target": "Agent-8jyTp",
        "targetHandle": "{≈ìfieldName≈ì:≈ìtools≈ì,≈ìid≈ì:≈ìAgent-8jyTp≈ì,≈ìinputTypes≈ì:[≈ìTool≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CSVAgent",
            "id": "CSVAgent-A8Fx7",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "StructuredOutput-ktP0P",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CSVAgent-A8Fx7{≈ìdataType≈ì:≈ìCSVAgent≈ì,≈ìid≈ì:≈ìCSVAgent-A8Fx7≈ì,≈ìname≈ì:≈ìresponse≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}-StructuredOutput-ktP0P{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìStructuredOutput-ktP0P≈ì,≈ìinputTypes≈ì:[≈ìMessage≈ì],≈ìtype≈ì:≈ìstr≈ì}",
        "selected": false,
        "source": "CSVAgent-A8Fx7",
        "sourceHandle": "{≈ìdataType≈ì:≈ìCSVAgent≈ì,≈ìid≈ì:≈ìCSVAgent-A8Fx7≈ì,≈ìname≈ì:≈ìresponse≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}",
        "target": "StructuredOutput-ktP0P",
        "targetHandle": "{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìStructuredOutput-ktP0P≈ì,≈ìinputTypes≈ì:[≈ìMessage≈ì],≈ìtype≈ì:≈ìstr≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-8FDNi",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "StructuredOutput-ktP0P",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LanguageModelComponent-8FDNi{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-8FDNi≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}-StructuredOutput-ktP0P{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìStructuredOutput-ktP0P≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "LanguageModelComponent-8FDNi",
        "sourceHandle": "{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-8FDNi≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}",
        "target": "StructuredOutput-ktP0P",
        "targetHandle": "{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìStructuredOutput-ktP0P≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "StructuredOutput",
            "id": "StructuredOutput-ktP0P",
            "name": "structured_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "structured_data",
            "id": "PlotlyVisualizerComponent-02C8e",
            "inputTypes": [
              "Data",
              "Message",
              "dict",
              "str"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-StructuredOutput-ktP0P{≈ìdataType≈ì:≈ìStructuredOutput≈ì,≈ìid≈ì:≈ìStructuredOutput-ktP0P≈ì,≈ìname≈ì:≈ìstructured_output≈ì,≈ìoutput_types≈ì:[≈ìData≈ì]}-PlotlyVisualizerComponent-02C8e{≈ìfieldName≈ì:≈ìstructured_data≈ì,≈ìid≈ì:≈ìPlotlyVisualizerComponent-02C8e≈ì,≈ìinputTypes≈ì:[≈ìData≈ì,≈ìMessage≈ì,≈ìdict≈ì,≈ìstr≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "StructuredOutput-ktP0P",
        "sourceHandle": "{≈ìdataType≈ì:≈ìStructuredOutput≈ì,≈ìid≈ì:≈ìStructuredOutput-ktP0P≈ì,≈ìname≈ì:≈ìstructured_output≈ì,≈ìoutput_types≈ì:[≈ìData≈ì]}",
        "target": "PlotlyVisualizerComponent-02C8e",
        "targetHandle": "{≈ìfieldName≈ì:≈ìstructured_data≈ì,≈ìid≈ì:≈ìPlotlyVisualizerComponent-02C8e≈ì,≈ìinputTypes≈ì:[≈ìData≈ì,≈ìMessage≈ì,≈ìdict≈ì,≈ìstr≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-EdzLE",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "CSVAgent-UoaOb",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LanguageModelComponent-EdzLE{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-EdzLE≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}-CSVAgent-UoaOb{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìCSVAgent-UoaOb≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "LanguageModelComponent-EdzLE",
        "sourceHandle": "{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-EdzLE≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}",
        "target": "CSVAgent-UoaOb",
        "targetHandle": "{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìCSVAgent-UoaOb≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CSVAgent",
            "id": "CSVAgent-UoaOb",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "StructuredOutput-RfnPp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CSVAgent-UoaOb{≈ìdataType≈ì:≈ìCSVAgent≈ì,≈ìid≈ì:≈ìCSVAgent-UoaOb≈ì,≈ìname≈ì:≈ìresponse≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}-StructuredOutput-RfnPp{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìStructuredOutput-RfnPp≈ì,≈ìinputTypes≈ì:[≈ìMessage≈ì],≈ìtype≈ì:≈ìstr≈ì}",
        "selected": false,
        "source": "CSVAgent-UoaOb",
        "sourceHandle": "{≈ìdataType≈ì:≈ìCSVAgent≈ì,≈ìid≈ì:≈ìCSVAgent-UoaOb≈ì,≈ìname≈ì:≈ìresponse≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}",
        "target": "StructuredOutput-RfnPp",
        "targetHandle": "{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìStructuredOutput-RfnPp≈ì,≈ìinputTypes≈ì:[≈ìMessage≈ì],≈ìtype≈ì:≈ìstr≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PlotlyVisualizerComponent",
            "id": "PlotlyVisualizerComponent-6JNkF",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-rCmRA",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-PlotlyVisualizerComponent-6JNkF{≈ìdataType≈ì:≈ìPlotlyVisualizerComponent≈ì,≈ìid≈ì:≈ìPlotlyVisualizerComponent-6JNkF≈ì,≈ìname≈ì:≈ìoutput≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}-ChatOutput-rCmRA{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìChatOutput-rCmRA≈ì,≈ìinputTypes≈ì:[≈ìData≈ì,≈ìDataFrame≈ì,≈ìMessage≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "PlotlyVisualizerComponent-6JNkF",
        "sourceHandle": "{≈ìdataType≈ì:≈ìPlotlyVisualizerComponent≈ì,≈ìid≈ì:≈ìPlotlyVisualizerComponent-6JNkF≈ì,≈ìname≈ì:≈ìoutput≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}",
        "target": "ChatOutput-rCmRA",
        "targetHandle": "{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìChatOutput-rCmRA≈ì,≈ìinputTypes≈ì:[≈ìData≈ì,≈ìDataFrame≈ì,≈ìMessage≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-dPwan",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CSVAgent-UoaOb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-dPwan{≈ìdataType≈ì:≈ìChatInput≈ì,≈ìid≈ì:≈ìChatInput-dPwan≈ì,≈ìname≈ì:≈ìmessage≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}-CSVAgent-UoaOb{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìCSVAgent-UoaOb≈ì,≈ìinputTypes≈ì:[≈ìMessage≈ì],≈ìtype≈ì:≈ìstr≈ì}",
        "selected": false,
        "source": "ChatInput-dPwan",
        "sourceHandle": "{≈ìdataType≈ì:≈ìChatInput≈ì,≈ìid≈ì:≈ìChatInput-dPwan≈ì,≈ìname≈ì:≈ìmessage≈ì,≈ìoutput_types≈ì:[≈ìMessage≈ì]}",
        "target": "CSVAgent-UoaOb",
        "targetHandle": "{≈ìfieldName≈ì:≈ìinput_value≈ì,≈ìid≈ì:≈ìCSVAgent-UoaOb≈ì,≈ìinputTypes≈ì:[≈ìMessage≈ì],≈ìtype≈ì:≈ìstr≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-EdzLE",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "StructuredOutput-RfnPp",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LanguageModelComponent-EdzLE{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-EdzLE≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}-StructuredOutput-RfnPp{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìStructuredOutput-RfnPp≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "LanguageModelComponent-EdzLE",
        "sourceHandle": "{≈ìdataType≈ì:≈ìLanguageModelComponent≈ì,≈ìid≈ì:≈ìLanguageModelComponent-EdzLE≈ì,≈ìname≈ì:≈ìmodel_output≈ì,≈ìoutput_types≈ì:[≈ìLanguageModel≈ì]}",
        "target": "StructuredOutput-RfnPp",
        "targetHandle": "{≈ìfieldName≈ì:≈ìllm≈ì,≈ìid≈ì:≈ìStructuredOutput-RfnPp≈ì,≈ìinputTypes≈ì:[≈ìLanguageModel≈ì],≈ìtype≈ì:≈ìother≈ì}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "StructuredOutput",
            "id": "StructuredOutput-RfnPp",
            "name": "visualization_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "structured_data",
            "id": "PlotlyVisualizerComponent-6JNkF",
            "inputTypes": [
              "Data",
              "Message",
              "dict",
              "str"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-StructuredOutput-RfnPp{≈ìdataType≈ì:≈ìStructuredOutput≈ì,≈ìid≈ì:≈ìStructuredOutput-RfnPp≈ì,≈ìname≈ì:≈ìvisualization_data≈ì,≈ìoutput_types≈ì:[≈ìData≈ì]}-PlotlyVisualizerComponent-6JNkF{≈ìfieldName≈ì:≈ìstructured_data≈ì,≈ìid≈ì:≈ìPlotlyVisualizerComponent-6JNkF≈ì,≈ìinputTypes≈ì:[≈ìData≈ì,≈ìMessage≈ì,≈ìdict≈ì,≈ìstr≈ì],≈ìtype≈ì:≈ìother≈ì}",
        "selected": false,
        "source": "StructuredOutput-RfnPp",
        "sourceHandle": "{≈ìdataType≈ì:≈ìStructuredOutput≈ì,≈ìid≈ì:≈ìStructuredOutput-RfnPp≈ì,≈ìname≈ì:≈ìvisualization_data≈ì,≈ìoutput_types≈ì:[≈ìData≈ì]}",
        "target": "PlotlyVisualizerComponent-6JNkF",
        "targetHandle": "{≈ìfieldName≈ì:≈ìstructured_data≈ì,≈ìid≈ì:≈ìPlotlyVisualizerComponent-6JNkF≈ì,≈ìinputTypes≈ì:[≈ìData≈ì,≈ìMessage≈ì,≈ìdict≈ì,≈ìstr≈ì],≈ìtype≈ì:≈ìother≈ì}"
      }
    ],
    "nodes": [
      {
        "data": {
          "description": "Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
          "display_name": "URL",
          "id": "URL-dZnaI",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
            "display_name": "URL",
            "documentation": "",
            "edited": false,
            "field_order": [
              "urls",
              "format",
              "separator",
              "clean_extra_whitespace"
            ],
            "frozen": false,
            "icon": "layout-template",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_extra_whitespace": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Clean Extra Whitespace",
                "dynamic": false,
                "info": "Whether to clean excessive blank lines in the text output. Only applies to 'Text' format.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_extra_whitespace",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport json\nimport re\n\nimport aiohttp\nfrom langchain_community.document_loaders import AsyncHtmlLoader, WebBaseLoader\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, MessageTextInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\n\n\nclass URLComponent(Component):\n    display_name = \"URL\"\n    description = (\n        \"Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, \"\n        \"or JSON, with options for cleaning and separating multiple outputs.\"\n    )\n    icon = \"layout-template\"\n    name = \"URL\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            tool_mode=True,\n            placeholder=\"Enter a URL...\",\n            list_add_label=\"Add URL\",\n        ),\n        DropdownInput(\n            name=\"format\",\n            display_name=\"Output Format\",\n            info=(\n                \"Output Format. Use 'Text' to extract text from the HTML, 'Raw HTML' for the raw HTML \"\n                \"content, or 'JSON' to extract JSON from the HTML.\"\n            ),\n            options=[\"Text\", \"Raw HTML\", \"JSON\"],\n            value=\"Text\",\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            value=\"\\n\\n\",\n            show=True,\n            info=(\n                \"Specify the separator to use between multiple outputs. Default for Text is '\\\\n\\\\n'. \"\n                \"Default for Raw HTML is '\\\\n<!-- Separator -->\\\\n'.\"\n            ),\n        ),\n        BoolInput(\n            name=\"clean_extra_whitespace\",\n            display_name=\"Clean Extra Whitespace\",\n            value=True,\n            show=True,\n            info=\"Whether to clean excessive blank lines in the text output. Only applies to 'Text' format.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Text\", name=\"text\", method=\"fetch_content_text\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    async def validate_json_content(self, url: str) -> bool:\n        \"\"\"Validates if the URL content is actually JSON.\"\"\"\n        try:\n            async with aiohttp.ClientSession() as session, session.get(url) as response:\n                http_ok = 200\n                if response.status != http_ok:\n                    return False\n\n                content = await response.text()\n                try:\n                    json.loads(content)\n                except json.JSONDecodeError:\n                    return False\n                else:\n                    return True\n        except (aiohttp.ClientError, asyncio.TimeoutError):\n            # Log specific error for debugging if needed\n            return False\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        \"\"\"Dynamically update fields based on selected format.\"\"\"\n        if field_name == \"format\":\n            is_text_mode = field_value == \"Text\"\n            is_json_mode = field_value == \"JSON\"\n            build_config[\"separator\"][\"value\"] = \"\\n\\n\" if is_text_mode else \"\\n<!-- Separator -->\\n\"\n            build_config[\"clean_extra_whitespace\"][\"show\"] = is_text_mode\n            build_config[\"separator\"][\"show\"] = not is_json_mode\n        return build_config\n\n    def ensure_url(self, string: str) -> str:\n        \"\"\"Ensures the given string is a valid URL.\"\"\"\n        if not string.startswith((\"http://\", \"https://\")):\n            string = \"http://\" + string\n\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\"\n            r\"(www\\.)?\"\n            r\"([a-zA-Z0-9.-]+)\"\n            r\"(\\.[a-zA-Z]{2,})?\"\n            r\"(:\\d+)?\"\n            r\"(\\/[^\\s]*)?$\",\n            re.IGNORECASE,\n        )\n\n        error_msg = \"Invalid URL - \" + string\n        if not url_regex.match(string):\n            raise ValueError(error_msg)\n\n        return string\n\n    def fetch_content(self) -> list[Data]:\n        \"\"\"Fetch content based on selected format.\"\"\"\n        urls = list({self.ensure_url(url.strip()) for url in self.urls if url.strip()})\n\n        no_urls_msg = \"No valid URLs provided.\"\n        if not urls:\n            raise ValueError(no_urls_msg)\n\n        # If JSON format is selected, validate JSON content first\n        if self.format == \"JSON\":\n            for url in urls:\n                is_json = asyncio.run(self.validate_json_content(url))\n                if not is_json:\n                    error_msg = \"Invalid JSON content from URL - \" + url\n                    raise ValueError(error_msg)\n\n        if self.format == \"Raw HTML\":\n            loader = AsyncHtmlLoader(web_path=urls, encoding=\"utf-8\")\n        else:\n            loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\n\n        docs = loader.load()\n\n        if self.format == \"JSON\":\n            data = []\n            for doc in docs:\n                try:\n                    json_content = json.loads(doc.page_content)\n                    data_dict = {\"text\": json.dumps(json_content, indent=2), **json_content, **doc.metadata}\n                    data.append(Data(**data_dict))\n                except json.JSONDecodeError as err:\n                    source = doc.metadata.get(\"source\", \"unknown URL\")\n                    error_msg = \"Invalid JSON content from \" + source\n                    raise ValueError(error_msg) from err\n            return data\n\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\n\n    def fetch_content_text(self) -> Message:\n        \"\"\"Fetch content and return as formatted text.\"\"\"\n        data = self.fetch_content()\n\n        if self.format == \"JSON\":\n            text_list = [item.text for item in data]\n            result = \"\\n\".join(text_list)\n        else:\n            text_list = [item.text for item in data]\n            if self.format == \"Text\" and self.clean_extra_whitespace:\n                text_list = [re.sub(r\"\\n{3,}\", \"\\n\\n\", text) for text in text_list]\n            result = self.separator.join(text_list)\n\n        self.status = result\n        return Message(text=result)\n\n    def as_dataframe(self) -> DataFrame:\n        \"\"\"Return fetched content as a DataFrame.\"\"\"\n        return DataFrame(self.fetch_content())\n"
              },
              "format": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Output Format",
                "dynamic": false,
                "info": "Output Format. Use 'Text' to extract text from the HTML, 'Raw HTML' for the raw HTML content, or 'JSON' to extract JSON from the HTML.",
                "name": "format",
                "options": [
                  "Text",
                  "Raw HTML",
                  "JSON"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Text"
              },
              "separator": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "Specify the separator to use between multiple outputs. Default for Text is '\\n\\n'. Default for Raw HTML is '\\n<!-- Separator -->\\n'.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n\n"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "urls": {
                        "default": "",
                        "description": "",
                        "items": {
                          "type": "string"
                        },
                        "title": "Urls",
                        "type": "array"
                      }
                    },
                    "description": "URL. fetch_content() - Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
                    "display_description": "URL. fetch_content() - Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
                    "display_name": "fetch_content",
                    "name": "fetch_content",
                    "status": true,
                    "tags": [
                      "fetch_content"
                    ]
                  },
                  {
                    "args": {
                      "urls": {
                        "default": "",
                        "description": "",
                        "items": {
                          "type": "string"
                        },
                        "title": "Urls",
                        "type": "array"
                      }
                    },
                    "description": "URL. fetch_content_text() - Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
                    "display_description": "URL. fetch_content_text() - Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
                    "display_name": "fetch_content_text",
                    "name": "fetch_content_text",
                    "status": true,
                    "tags": [
                      "fetch_content_text"
                    ]
                  },
                  {
                    "args": {
                      "urls": {
                        "default": "",
                        "description": "",
                        "items": {
                          "type": "string"
                        },
                        "title": "Urls",
                        "type": "array"
                      }
                    },
                    "description": "URL. as_dataframe() - Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
                    "display_description": "URL. as_dataframe() - Load and retrieve data from specified URLs. Supports output in plain text, raw HTML, or JSON, with options for cleaning and separating multiple outputs.",
                    "display_name": "as_dataframe",
                    "name": "as_dataframe",
                    "status": true,
                    "tags": [
                      "as_dataframe"
                    ]
                  }
                ]
              },
              "urls": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URLs",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add URL",
                "load_from_db": false,
                "name": "urls",
                "placeholder": "Enter a URL...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": true
          },
          "type": "URL"
        },
        "id": "URL-dZnaI",
        "measured": {
          "height": 521,
          "width": 320
        },
        "position": {
          "x": 1059.6765445844026,
          "y": 439
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-uw5VD",
          "node": {
            "description": "# üìñ README\nRun an Agent with URL and Calculator tools available for its use. \nThe Agent decides which tool to use to solve a problem.\n## Quick start\n\n1. Add your OpenAI API key to the Agent.\n2. Open the Playground and chat with the Agent. Request some information about a recipe, and then ask to add two numbers together. In the responses, the Agent will use different tools to solve different problems.\n\n## Next steps\nConnect more tools to the Agent to create your perfect assistant.\n\nFor more, see the [Langflow docs](https://docs.langflow.org/agents-tool-calling-agent-component).",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "id": "note-uw5VD",
        "measured": {
          "height": 630,
          "width": 325
        },
        "position": {
          "x": 604.9999999999999,
          "y": 1614.445582022099
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "CalculatorComponent-3aZuf",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "tools",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Perform basic arithmetic operations on a given expression.",
            "display_name": "Calculator",
            "documentation": "",
            "edited": false,
            "field_order": [
              "expression"
            ],
            "frozen": false,
            "icon": "calculator",
            "key": "CalculatorComponent",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import ast\nimport operator\nfrom collections.abc import Callable\n\nfrom langflow.custom import Component\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\n\n\nclass CalculatorComponent(Component):\n    display_name = \"Calculator\"\n    description = \"Perform basic arithmetic operations on a given expression.\"\n    icon = \"calculator\"\n\n    # Cache operators dictionary as a class variable\n    OPERATORS: dict[type[ast.operator], Callable] = {\n        ast.Add: operator.add,\n        ast.Sub: operator.sub,\n        ast.Mult: operator.mul,\n        ast.Div: operator.truediv,\n        ast.Pow: operator.pow,\n    }\n\n    inputs = [\n        MessageTextInput(\n            name=\"expression\",\n            display_name=\"Expression\",\n            info=\"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"result\", type_=Data, method=\"evaluate_expression\"),\n    ]\n\n    def _eval_expr(self, node: ast.AST) -> float:\n        \"\"\"Evaluate an AST node recursively.\"\"\"\n        if isinstance(node, ast.Constant):\n            if isinstance(node.value, int | float):\n                return float(node.value)\n            error_msg = f\"Unsupported constant type: {type(node.value).__name__}\"\n            raise TypeError(error_msg)\n        if isinstance(node, ast.Num):  # For backwards compatibility\n            if isinstance(node.n, int | float):\n                return float(node.n)\n            error_msg = f\"Unsupported number type: {type(node.n).__name__}\"\n            raise TypeError(error_msg)\n\n        if isinstance(node, ast.BinOp):\n            op_type = type(node.op)\n            if op_type not in self.OPERATORS:\n                error_msg = f\"Unsupported binary operator: {op_type.__name__}\"\n                raise TypeError(error_msg)\n\n            left = self._eval_expr(node.left)\n            right = self._eval_expr(node.right)\n            return self.OPERATORS[op_type](left, right)\n\n        error_msg = f\"Unsupported operation or expression type: {type(node).__name__}\"\n        raise TypeError(error_msg)\n\n    def evaluate_expression(self) -> Data:\n        \"\"\"Evaluate the mathematical expression and return the result.\"\"\"\n        try:\n            tree = ast.parse(self.expression, mode=\"eval\")\n            result = self._eval_expr(tree.body)\n\n            formatted_result = f\"{float(result):.6f}\".rstrip(\"0\").rstrip(\".\")\n            self.log(f\"Calculation result: {formatted_result}\")\n\n            self.status = formatted_result\n            return Data(data={\"result\": formatted_result})\n\n        except ZeroDivisionError:\n            error_message = \"Error: Division by zero\"\n            self.status = error_message\n            return Data(data={\"error\": error_message, \"input\": self.expression})\n\n        except (SyntaxError, TypeError, KeyError, ValueError, AttributeError, OverflowError) as e:\n            error_message = f\"Invalid expression: {e!s}\"\n            self.status = error_message\n            return Data(data={\"error\": error_message, \"input\": self.expression})\n\n    def build(self):\n        \"\"\"Return the main evaluation function.\"\"\"\n        return self.evaluate_expression\n"
              },
              "expression": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Expression",
                "dynamic": false,
                "info": "The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "expression",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "expression": {
                        "default": "",
                        "description": "The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').",
                        "title": "Expression",
                        "type": "string"
                      }
                    },
                    "description": "CalculatorComponent. evaluate_expression() - Perform basic arithmetic operations on a given expression.",
                    "display_description": "CalculatorComponent. evaluate_expression() - Perform basic arithmetic operations on a given expression.",
                    "display_name": "evaluate_expression",
                    "name": "evaluate_expression",
                    "status": true,
                    "tags": [
                      "evaluate_expression"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "CalculatorComponent"
        },
        "id": "CalculatorComponent-3aZuf",
        "measured": {
          "height": 247,
          "width": 320
        },
        "position": {
          "x": 1066.6134916192354,
          "y": 1057.4097719447282
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-dPwan",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "inputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatInput",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "id": "ChatInput-dPwan",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 1263.041890096155,
          "y": 6760.974834169188
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-rCmRA",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "outputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "id": "ChatOutput-rCmRA",
        "measured": {
          "height": 191,
          "width": 320
        },
        "position": {
          "x": 3378.4531684960903,
          "y": 7410.202860851881
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonREPLComponent-xgK0n",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "A Python code executor that lets you run Python code with specific imported modules. Remember to always use print() to see your results. Example: print(df.head())",
            "display_name": "Python REPL",
            "documentation": "",
            "edited": false,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "Python",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import importlib\n\nfrom langchain_experimental.utilities import PythonREPL\n\nfrom langflow.custom import Component\nfrom langflow.io import CodeInput, Output, StrInput\nfrom langflow.schema import Data\n\n\nclass PythonREPLComponent(Component):\n    display_name = \"Python REPL\"\n    description = (\n        \"A Python code executor that lets you run Python code with specific imported modules. \"\n        \"Remember to always use print() to see your results. Example: print(df.head())\"\n    )\n    icon = \"Python\"\n\n    inputs = [\n        StrInput(\n            name=\"global_imports\",\n            display_name=\"Global Imports\",\n            info=\"A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.\",\n            value=\"math,pandas\",\n            required=True,\n        ),\n        CodeInput(\n            name=\"python_code\",\n            display_name=\"Python Code\",\n            info=\"The Python code to execute. Only modules specified in Global Imports can be used.\",\n            value=\"print('Hello, World!')\",\n            tool_mode=True,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=Data,\n            method=\"run_python_repl\",\n        ),\n    ]\n\n    def get_globals(self, global_imports: str | list[str]) -> dict:\n        \"\"\"Create a globals dictionary with only the specified allowed imports.\"\"\"\n        global_dict = {}\n\n        try:\n            if isinstance(global_imports, str):\n                modules = [module.strip() for module in global_imports.split(\",\")]\n            elif isinstance(global_imports, list):\n                modules = global_imports\n            else:\n                msg = \"global_imports must be either a string or a list\"\n                raise TypeError(msg)\n\n            for module in modules:\n                try:\n                    imported_module = importlib.import_module(module)\n                    global_dict[imported_module.__name__] = imported_module\n                except ImportError as e:\n                    msg = f\"Could not import module {module}: {e!s}\"\n                    raise ImportError(msg) from e\n\n        except Exception as e:\n            self.log(f\"Error in global imports: {e!s}\")\n            raise\n        else:\n            self.log(f\"Successfully imported modules: {list(global_dict.keys())}\")\n            return global_dict\n\n    def run_python_repl(self) -> Data:\n        try:\n            globals_ = self.get_globals(self.global_imports)\n            python_repl = PythonREPL(_globals=globals_)\n            result = python_repl.run(self.python_code)\n            result = result.strip() if result else \"\"\n\n            self.log(\"Code execution completed successfully\")\n            return Data(data={\"result\": result})\n\n        except ImportError as e:\n            error_message = f\"Import Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except SyntaxError as e:\n            error_message = f\"Syntax Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except (NameError, TypeError, ValueError) as e:\n            error_message = f\"Error during execution: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n    def build(self):\n        return self.run_python_repl\n"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Global Imports",
                "dynamic": false,
                "info": "A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas, matplotlib"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python Code",
                "dynamic": false,
                "info": "The Python code to execute. Only modules specified in Global Imports can be used.",
                "list": false,
                "list_add_label": "Add More",
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "print('Hello, World!')"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "python_code": {
                        "description": "The Python code to execute. Only modules specified in Global Imports can be used.",
                        "title": "Python Code",
                        "type": "string"
                      }
                    },
                    "description": "PythonREPLComponent. run_python_repl - A Python code executor that lets you run Python code with specific imported modules. Remember to always use print() to see your results. Example: print(df.head())",
                    "display_description": "PythonREPLComponent. run_python_repl - A Python code executor that lets you run Python code with specific imported modules. Remember to always use print() to see your results. Example: print(df.head())",
                    "display_name": "run_python_repl",
                    "name": "run_python_repl",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "run_python_repl"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "PythonREPLComponent"
        },
        "id": "PythonREPLComponent-xgK0n",
        "measured": {
          "height": 369,
          "width": 320
        },
        "position": {
          "x": 969.7418640246173,
          "y": 1394.6325694869029
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ImageDisplayComponent-c8ZK1",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Displays bar plots generated by the Bar Plot Generator tool",
            "display_name": "Bar Plot Display",
            "documentation": "",
            "edited": true,
            "field_order": [
              "agent_response"
            ],
            "frozen": false,
            "icon": "image",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Displayed Image",
                "hidden": null,
                "method": "display_image",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent_response": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Agent Response",
                "dynamic": false,
                "info": "The response message from the agent containing image data",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent_response",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema import Data, Message\n\nclass ImageDisplayComponent(Component):\n    display_name = \"Bar Plot Display\"\n    description = \"Displays bar plots generated by the Bar Plot Generator tool\"\n    icon = \"image\"\n    \n    inputs = [\n        MessageInput(\n            name=\"agent_response\",\n            display_name=\"Agent Response\",\n            info=\"The response message from the agent containing image data\"\n        ),\n    ]\n    \n    outputs = [\n        Output(display_name=\"Displayed Image\", name=\"output\", method=\"display_image\"),\n    ]\n    \n    def display_image(self) -> Message:\n        try:\n            print(\"ImageDisplayComponent: Processing agent response\")\n            response = self.agent_response\n            \n            # Extract the tool output that contains our image data\n            tool_output = None\n            if hasattr(response, \"content_blocks\") and response.content_blocks:\n                content_block = response.content_blocks[0]\n                if hasattr(content_block, \"contents\") and len(content_block.contents) > 1:\n                    tool_content = content_block.contents[1]\n                    if hasattr(tool_content, \"type\") and tool_content.type == \"tool_use\":\n                        if hasattr(tool_content, \"output\") and isinstance(tool_content.output, dict):\n                            tool_output = tool_content.output.get(\"value\", {})\n            \n            print(f\"ImageDisplayComponent: Found tool output: {type(tool_output)}\")\n            \n            # Check if we have a dictionary with image_base64\n            if isinstance(tool_output, dict) and \"image_base64\" in tool_output:\n                print(\"ImageDisplayComponent: Found base64 image data\")\n                base64_image = tool_output[\"image_base64\"]\n                \n                # Create a message with the base64 image\n                message = Message(\n                    text=f\"Here's your bar plot for {tool_output.get('title', 'data')}:\",\n                    sender=\"System\",\n                    files=[base64_image]\n                )\n                return message\n            else:\n                print(\"ImageDisplayComponent: No base64 image found in tool output\")\n                return Message(text=\"Could not find image data in the expected format\")\n            \n        except Exception as e:\n            import traceback\n            print(f\"ImageDisplayComponent error: {e}\")\n            print(traceback.format_exc())\n            return Message(text=f\"Error displaying image: {e}\")\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ImageDisplayComponent"
        },
        "id": "ImageDisplayComponent-c8ZK1",
        "measured": {
          "height": 249,
          "width": 320
        },
        "position": {
          "x": 2486.195492372445,
          "y": 1633.2732182813693
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PuppyImageComponent-hwrDG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Displays a puppy image in the chat playground.",
            "display_name": "Puppy Image Display",
            "documentation": "http://docs.langflow.org/components/custom",
            "edited": true,
            "field_order": [
              "message_text"
            ],
            "frozen": false,
            "icon": "image",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "hidden": null,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\nfrom langflow.schema.message import Message\nfrom langflow.schema.content_block import ContentBlock\nfrom langflow.schema.content_types import TextContent, MediaContent\nimport ast\n\nclass PuppyImageComponent(Component):\n    display_name = \"Puppy Image Display\"\n    description = \"Displays a puppy image in the chat playground.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"image\"\n    name = \"PuppyImageComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"message_text\",\n            display_name=\"Message Text\",\n            info=\"Text message to accompany the puppy image\",\n            value=\"Here's a cute puppy!\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Message:\n        # After examining LangFlow's behavior, the key might be to include the image\n        # directly in the message text using markdown syntax\n        \n        image_url = \"https://i.pinimg.com/736x/3d/b4/af/3db4afc15b5c1c558ab2e2c1042012e6.jpg\"\n        \n        # Create markdown text with the image embedded\n        markdown_text = f\"{self.message_text}\\n\\n![Puppy]({image_url})\"\n        \n        # Create the message with the markdown text\n        message = Message(\n            text=markdown_text,  # Put markdown with image directly in the text\n            sender=\"Bot\",\n            # No content blocks - rely on the markdown in the text\n        )\n        \n        self.status = message\n        return message"
              },
              "message_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message Text",
                "dynamic": false,
                "info": "Text message to accompany the puppy image",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message_text",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PuppyImageComponent"
        },
        "id": "PuppyImageComponent-hwrDG",
        "measured": {
          "height": 249,
          "width": 320
        },
        "position": {
          "x": 2221.3275122122627,
          "y": 2368.0099961134156
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SimplePlotlyBarChartComponent-zBz6K",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a bar chart with hardcoded data using Plotly",
            "display_name": "Simple Plotly Bar Chart",
            "documentation": "",
            "edited": true,
            "field_order": [
              "chart_title"
            ],
            "frozen": false,
            "icon": "chart-bar",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chart_title": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Chart Title",
                "dynamic": false,
                "info": "Title for the bar chart",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chart_title",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Sample Bar Chart"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nimport plotly.express as px\nimport io\nimport base64\nimport tempfile\nimport os\n\nclass SimplePlotlyBarChartComponent(Component):\n    display_name = \"Simple Plotly Bar Chart\"\n    description = \"Creates a bar chart with hardcoded data using Plotly\"\n    icon = \"chart-bar\"\n    name = \"SimplePlotlyBarChartComponent\"\n    \n    inputs = [\n        MessageTextInput(\n            name=\"chart_title\",\n            display_name=\"Chart Title\",\n            info=\"Title for the bar chart\",\n            value=\"Sample Bar Chart\",\n            tool_mode=True,\n        ),\n    ]\n    \n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n    \n    def build_output(self) -> Message:\n        # Hardcoded data for the bar chart\n        categories = [\"Category A\", \"Category B\", \"Category C\", \"Category D\", \"Category E\"]\n        values = [23, 45, 56, 78, 32]\n        \n        # Create the Plotly figure\n        fig = px.bar(x=categories, y=values, title=self.chart_title)\n        \n        # Customize the figure\n        fig.update_layout(\n            xaxis_title=\"Categories\",\n            yaxis_title=\"Values\",\n            template=\"plotly_white\",\n        )\n        \n        # Save plot to a temporary file\n        temp_dir = tempfile.gettempdir()\n        file_name = f\"barplot_{hash(self.chart_title)}.png\"\n        img_path = os.path.join(temp_dir, file_name)\n        \n        # Write the image to the file\n        fig.write_image(img_path)\n        \n        # Create a base64 version as well\n        img_bytes = fig.to_image(format=\"png\")\n        img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n        base64_url = f\"data:image/png;base64,{img_base64}\"\n        \n        # Create the markdown with the embedded image\n        markdown_text = f\"{self.chart_title}\\n\\n![Bar Chart]({base64_url})\"\n        \n        # Create the message\n        message = Message(\n            text=markdown_text,\n            sender=\"Bot\",\n        )\n        \n        self.status = message\n        return message"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "chart_title": {
                        "default": "Sample Bar Chart",
                        "description": "Title for the bar chart",
                        "title": "Chart Title",
                        "type": "string"
                      }
                    },
                    "description": "SimplePlotlyBarChartComponent. build_output - Creates a bar chart with hardcoded data using Plotly",
                    "display_description": "SimplePlotlyBarChartComponent. build_output - Creates a bar chart with hardcoded data using Plotly",
                    "display_name": "build_output",
                    "name": "build_output",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "build_output"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "SimplePlotlyBarChartComponent"
        },
        "id": "SimplePlotlyBarChartComponent-zBz6K",
        "measured": {
          "height": 247,
          "width": 320
        },
        "position": {
          "x": 1521.8619388087031,
          "y": 3332.6775120463317
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-qAI2U",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": null,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": false,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "id": "Agent-qAI2U",
        "measured": {
          "height": 621,
          "width": 320
        },
        "position": {
          "x": 2343.9501411017277,
          "y": 2894.5437505784266
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SimpleCSVAgent-xm5Xs",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "A two-stage CSV agent that analyzes data and creates visualizations using LangGraph.",
            "display_name": "SimpleCSVAgent",
            "documentation": "https://docs.langgraph.ai/getting-started",
            "edited": true,
            "field_order": [
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "llm",
              "path",
              "input_value",
              "pandas_kwargs"
            ],
            "frozen": false,
            "icon": "LangChain",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": false,
                "method": "build_agent_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.agents.agent import LCAgentComponent\nfrom langflow.inputs import FileInput, HandleInput\nfrom langflow.inputs.inputs import DictInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nimport pandas as pd\nimport os\nfrom typing_extensions import TypedDict\nfrom typing import Annotated, List\n\n# Import for Plotly and encoding\nimport plotly.express as px\nimport io\nimport base64\n\n# Import LangGraph components\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\nfrom langgraph.prebuilt import ToolNode, tools_condition\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langchain_core.tools import tool\nfrom langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n\n\nclass SimpleCSVAgentComponent(LCAgentComponent):\n    display_name = \"SimpleCSVAgent\"\n    description = \"A two-stage CSV agent that analyzes data and creates visualizations using LangGraph.\"\n    documentation = \"https://docs.langgraph.ai/getting-started\"\n    name = \"SimpleCSVAgent\"\n    icon = \"LangChain\"\n\n    inputs = [\n        *LCAgentComponent._base_inputs,\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"An LLM Model Object (It can be found in any LLM Component).\",\n        ),\n        FileInput(\n            name=\"path\",\n            display_name=\"File Path\",\n            file_types=[\"csv\"],\n            input_types=[\"str\", \"Message\"],\n            required=True,\n            info=\"A CSV File or File Path.\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input and extract info from the CSV File.\",\n            required=True,\n        ),\n        DictInput(\n            name=\"pandas_kwargs\",\n            display_name=\"Pandas Kwargs\",\n            info=\"Pandas Kwargs to be passed when reading the CSV.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response\", method=\"build_agent_response\"),\n    ]\n\n    def _path(self) -> str:\n        \"\"\"Get the path to the CSV file.\"\"\"\n        if isinstance(self.path, Message) and isinstance(self.path.text, str):\n            return self.path.text\n        return self.path\n\n    def _get_analysis_system_message(self):\n        \"\"\"Create a system message for the CSV analysis agent.\"\"\"\n        return \"\"\"You are a data analysis expert specializing in CSV dataset exploration.\n\nYour task is to use the analyze_csv_dataset tool to provide a comprehensive analysis of the CSV file.\nAfter receiving the analysis, summarize the most important insights about the data in a clear and concise way.\n\nFocus on highlighting:\n1. The overall structure of the dataset (size, dimensions)\n2. The most interesting columns and their characteristics\n3. Any patterns, unusual values, or potential issues in the data\n4. Suggestions for how this data might be used for analysis or visualization\n\nWhen you're finished with your analysis, the conversation will automatically continue to create a visualization.\n\"\"\"\n\n    def _get_visualization_system_message(self):\n        \"\"\"Create a system message for the visualization agent.\"\"\"\n        return \"\"\"You are a data visualization expert.\n\nBased on the CSV analysis that was just performed, your task is to:\n1. Use the generate_plotly_visualization tool to create a visualization of the data\n2. Explain what the visualization shows and how it relates to the insights from the analysis\n3. Suggest additional visualizations that might be useful for exploring this dataset further\n\nFocus on making your explanation clear and insightful, connecting the visualization to the data properties.\n\"\"\"\n\n    def _setup_csv_tool(self, data_path):\n        \"\"\"Set up a comprehensive CSV analysis tool.\"\"\"\n        \n        @tool\n        def analyze_csv_dataset(query: str = \"\") -> str:\n            \"\"\"\n            Perform a comprehensive analysis of the CSV dataset, providing detailed information\n            about the structure, content, and statistics of the data.\n            \n            Args:\n                query: The query text (not used but required for tool interface)\n            \n            Returns:\n                A detailed analysis of the CSV dataset\n            \"\"\"\n            try:\n                # Read the CSV file\n                if self.pandas_kwargs:\n                    df = pd.read_csv(data_path, **self.pandas_kwargs)\n                else:\n                    df = pd.read_csv(data_path)\n                \n                # Basic dataset information\n                row_count = len(df)\n                col_count = len(df.columns)\n                file_name = os.path.basename(data_path)\n                file_size = os.path.getsize(data_path) / 1024  # Size in KB\n                \n                # Column information\n                column_names = df.columns.tolist()\n                data_types = {}\n                missing_values = {}\n                unique_values = {}\n                numeric_stats = {}\n                top_values = {}\n                \n                for col in column_names:\n                    # Data type\n                    data_types[col] = str(df[col].dtype)\n                    \n                    # Missing values\n                    missing_count = df[col].isna().sum()\n                    missing_percent = (missing_count / row_count) * 100\n                    missing_values[col] = f\"{missing_count} ({missing_percent:.2f}%)\"\n                    \n                    # Unique values\n                    unique_count = df[col].nunique()\n                    unique_percent = (unique_count / row_count) * 100\n                    unique_values[col] = f\"{unique_count} ({unique_percent:.2f}%)\"\n                    \n                    # For numeric columns, compute statistics\n                    if pd.api.types.is_numeric_dtype(df[col]):\n                        try:\n                            stats = {\n                                \"min\": df[col].min(),\n                                \"max\": df[col].max(),\n                                \"mean\": df[col].mean(),\n                                \"median\": df[col].median(),\n                                \"std\": df[col].std()\n                            }\n                            numeric_stats[col] = stats\n                        except:\n                            # Handle case where numeric computation fails (e.g., mixed types)\n                            pass\n                    \n                    # Top values (for categorical or object columns)\n                    if pd.api.types.is_object_dtype(df[col]) or pd.api.types.is_categorical_dtype(df[col]):\n                        try:\n                            value_counts = df[col].value_counts().head(3)\n                            top_values[col] = [(val, count) for val, count in zip(value_counts.index, value_counts.values)]\n                        except:\n                            # Handle case where value_counts fails\n                            pass\n                \n                # Identify potential primary keys (columns with all unique values)\n                potential_keys = [col for col in column_names if df[col].nunique() == row_count and df[col].isna().sum() == 0]\n                \n                # Look for date columns\n                date_columns = []\n                for col in column_names:\n                    if 'date' in col.lower() or 'time' in col.lower():\n                        try:\n                            # Try to parse as datetime\n                            pd.to_datetime(df[col], errors='raise')\n                            date_columns.append(col)\n                        except:\n                            pass\n                \n                # Check for correlations in numeric columns\n                correlation = None\n                numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n                high_correlations = []\n                if len(numeric_cols) >= 2:\n                    try:\n                        correlation = df[numeric_cols].corr()\n                        # Find the highest correlations (excluding self-correlations)\n                        for i, col1 in enumerate(numeric_cols):\n                            for col2 in numeric_cols[i+1:]:\n                                corr_value = correlation.loc[col1, col2]\n                                if abs(corr_value) > 0.7:  # Arbitrary threshold for \"high\" correlation\n                                    high_correlations.append((col1, col2, corr_value))\n                    except:\n                        # Handle case where correlation computation fails\n                        pass\n                \n                # Prepare the analysis response\n                response = f\"# CSV Dataset Analysis: {file_name}\\n\\n\"\n                \n                # Basic information section\n                response += \"## Basic Information\\n\\n\"\n                response += f\"- **File Name**: {file_name}\\n\"\n                response += f\"- **File Size**: {file_size:.2f} KB\\n\"\n                response += f\"- **Rows**: {row_count}\\n\"\n                response += f\"- **Columns**: {col_count}\\n\"\n                if potential_keys:\n                    response += f\"- **Potential Primary Keys**: {', '.join(potential_keys)}\\n\"\n                if date_columns:\n                    response += f\"- **Date/Time Columns**: {', '.join(date_columns)}\\n\"\n                \n                # Column details section\n                response += \"\\n## Column Details\\n\\n\"\n                for col in column_names:\n                    response += f\"### {col}\\n\\n\"\n                    response += f\"- **Type**: {data_types[col]}\\n\"\n                    response += f\"- **Missing Values**: {missing_values[col]}\\n\"\n                    response += f\"- **Unique Values**: {unique_values[col]}\\n\"\n                    \n                    if col in numeric_stats:\n                        stats = numeric_stats[col]\n                        response += f\"- **Range**: {stats['min']} to {stats['max']}\\n\"\n                        response += f\"- **Mean**: {stats['mean']:.2f}\\n\"\n                        response += f\"- **Median**: {stats['median']:.2f}\\n\"\n                        response += f\"- **Standard Deviation**: {stats['std']:.2f}\\n\"\n                    \n                    if col in top_values and top_values[col]:\n                        response += \"- **Most Common Values**:\\n\"\n                        for val, count in top_values[col]:\n                            percent = (count / row_count) * 100\n                            val_str = str(val)\n                            if len(val_str) > 50:  # Truncate long values\n                                val_str = val_str[:47] + \"...\"\n                            response += f\"  - {val_str}: {count} ({percent:.2f}%)\\n\"\n                    \n                    response += \"\\n\"\n                \n                # Correlation insights if available\n                if high_correlations:\n                    response += \"## Correlation Insights\\n\\n\"\n                    response += \"Highly correlated numeric columns (|r| > 0.7):\\n\\n\"\n                    for col1, col2, corr in high_correlations:\n                        corr_type = \"positive\" if corr > 0 else \"negative\"\n                        response += f\"- **{col1}** and **{col2}** have a strong {corr_type} correlation (r = {corr:.2f})\\n\"\n                    response += \"\\n\"\n                \n                # Data sample\n                response += \"## Data Sample\\n\\n\"\n                response += \"```\\n\"\n                response += df.head(5).to_string(index=False)\n                response += \"\\n```\\n\\n\"\n                \n                # Add summary stats for all numeric columns in tabular format\n                if numeric_cols:\n                    response += \"## Summary Statistics (Numeric Columns)\\n\\n\"\n                    response += \"```\\n\"\n                    response += df[numeric_cols].describe().to_string()\n                    response += \"\\n```\\n\"\n                \n                return response\n                \n            except Exception as e:\n                return f\"Error analyzing CSV file: {str(e)}\"\n        \n        return [analyze_csv_dataset]\n\n    def _setup_plot_tool(self, data_path):\n        \"\"\"Set up a tool that creates a Plotly visualization of the CSV data.\"\"\"\n        \n        @tool\n        def generate_plotly_visualization(_: str = \"\") -> str:\n            \"\"\"\n            Generate a Plotly visualization of the CSV data.\n            \n            Args:\n                _: Placeholder parameter (not used)\n                \n            Returns:\n                A base64 encoded image of the Plotly visualization\n            \"\"\"\n            try:\n                # Read the CSV file\n                if self.pandas_kwargs:\n                    df = pd.read_csv(data_path, **self.pandas_kwargs)\n                else:\n                    df = pd.read_csv(data_path)\n                \n                # Determine the best columns to plot based on data types\n                numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n                categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n                \n                # First, check for Time worked and User columns for the common work tracking use case\n                if 'Time worked' in df.columns and 'User' in df.columns:\n                    # Create a bar chart of total hours by user\n                    user_hours = df.groupby('User')['Time worked'].sum().reset_index()\n                    user_hours = user_hours.sort_values('Time worked', ascending=False)\n                    \n                    fig = px.bar(\n                        user_hours,\n                        x='User',\n                        y='Time worked',\n                        title='Total Hours Worked by User',\n                        color='Time worked',\n                        color_continuous_scale='viridis'\n                    )\n                    \n                # Default plot is a scatter plot of the first two numeric columns if available\n                elif len(numeric_cols) >= 2:\n                    # Scatter plot of first two numeric columns\n                    fig = px.scatter(\n                        df.head(100),  # Limit to first 100 rows for performance\n                        x=numeric_cols[0],\n                        y=numeric_cols[1],\n                        title=f\"Scatter Plot: {numeric_cols[1]} vs {numeric_cols[0]}\",\n                        opacity=0.7,\n                        color=categorical_cols[0] if categorical_cols else None,\n                        hover_data=df.columns[:5].tolist()  # Include first 5 columns in hover data\n                    )\n                elif len(numeric_cols) == 1 and categorical_cols:\n                    # Box plot of numeric column grouped by first categorical column\n                    fig = px.box(\n                        df,\n                        x=categorical_cols[0],\n                        y=numeric_cols[0],\n                        title=f\"Box Plot: {numeric_cols[0]} by {categorical_cols[0]}\",\n                        color=categorical_cols[0]\n                    )\n                elif categorical_cols:\n                    # Bar chart of counts for first categorical column\n                    value_counts = df[categorical_cols[0]].value_counts().head(15)  # Top 15 categories\n                    fig = px.bar(\n                        x=value_counts.index,\n                        y=value_counts.values,\n                        title=f\"Count of {categorical_cols[0]} Values\",\n                        labels={\"x\": categorical_cols[0], \"y\": \"Count\"}\n                    )\n                else:\n                    # Fallback: simple line plot of row indices vs first column\n                    fig = px.line(\n                        df.head(50),\n                        x=df.index[:50],\n                        y=df.columns[0],\n                        title=f\"Line Plot of {df.columns[0]}\"\n                    )\n                \n                # Improve layout\n                fig.update_layout(\n                    template=\"plotly_white\",\n                    margin=dict(l=40, r=40, t=60, b=40),\n                    legend_title_text=\"\",\n                    xaxis_title=fig.layout.xaxis.title.text,\n                    yaxis_title=fig.layout.yaxis.title.text\n                )\n                \n                # Convert the figure to a PNG image and encode as base64\n                try:\n                    # First attempt with kaleido (standard method)\n                    buf = io.BytesIO()\n                    fig.write_image(buf, format=\"png\")\n                    img_b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n                    return f\"data:image/png;base64,{img_b64}\"\n                except Exception as plot_error:\n                    # If kaleido fails, try an alternative method\n                    # Create a very simple fallback plot without Plotly dependencies\n                    # This is a very basic ASCII plot\n                    if 'Time worked' in df.columns and 'User' in df.columns:\n                        user_hours = df.groupby('User')['Time worked'].sum().reset_index()\n                        user_hours = user_hours.sort_values('Time worked', ascending=False)\n                        \n                        plot_str = \"Total Hours Worked by User (ASCII Fallback Plot):\\n\\n\"\n                        max_hours = user_hours['Time worked'].max()\n                        scale_factor = 40 / max_hours if max_hours > 0 else 1\n                        \n                        for _, row in user_hours.iterrows():\n                            user = row['User']\n                            hours = row['Time worked']\n                            bar_length = int(hours * scale_factor)\n                            plot_str += f\"{user.ljust(10)}: {'#' * bar_length} ({hours:.2f} hours)\\n\"\n                        \n                        return f\"Error generating Plotly visualization: {plot_error}\\n\\n{plot_str}\"\n                    \n                    return f\"Error generating visualization: {plot_error}\"\n                \n            except Exception as e:\n                return f\"Error analyzing CSV data for visualization: {str(e)}\"\n        \n        return [generate_plotly_visualization]\n\n    def build_agent_response(self) -> Message:\n        \"\"\"\n        Build a comprehensive response using a two-stage LangGraph with analysis and visualization agents.\n        \"\"\"\n        try:\n            # Get the CSV path\n            csv_path = self._path()\n            \n            # Set up both the CSV analysis and plotting tools\n            csv_tools = self._setup_csv_tool(csv_path)\n            plot_tools = self._setup_plot_tool(csv_path)\n            all_tools = csv_tools + plot_tools\n            \n            # Create the LLM with all tools\n            llm_with_tools = self.llm.bind_tools(all_tools)\n            \n            # Define the state for LangGraph\n            class State(TypedDict):\n                messages: Annotated[List, add_messages]\n            \n            # Define the analysis agent node\n            def analysis_agent(state: State):\n                # Get the messages\n                messages = state[\"messages\"]\n                # We invoke the LLM with the tools\n                response = llm_with_tools.invoke(messages)\n                # Return the updated messages\n                return {\n                    \"messages\": [response]\n                }\n            \n            # Define the visualization agent node - simplified to directly call the visualization tool\n            def visualization_agent(state: State):\n                # First, try to create a visualization directly using the tool\n                try:\n                    # Read the CSV file\n                    if self.pandas_kwargs:\n                        df = pd.read_csv(csv_path, **self.pandas_kwargs)\n                    else:\n                        df = pd.read_csv(csv_path)\n                    \n                    # Determine the best columns to plot\n                    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n                    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n                    \n                    # Use 'Time worked' and 'User' if they exist\n                    if 'Time worked' in df.columns and 'User' in df.columns:\n                        # Create a bar chart of total hours by user\n                        user_hours = df.groupby('User')['Time worked'].sum().reset_index()\n                        user_hours = user_hours.sort_values('Time worked', ascending=False)\n                        \n                        fig = px.bar(\n                            user_hours,\n                            x='User',\n                            y='Time worked',\n                            title='Total Hours Worked by User',\n                            color='Time worked',\n                            color_continuous_scale='viridis'\n                        )\n                    elif len(numeric_cols) >= 2:\n                        # Scatter plot of first two numeric columns\n                        fig = px.scatter(\n                            df.head(100),\n                            x=numeric_cols[0],\n                            y=numeric_cols[1],\n                            title=f\"Scatter Plot: {numeric_cols[1]} vs {numeric_cols[0]}\"\n                        )\n                    elif len(numeric_cols) == 1 and categorical_cols:\n                        # Box plot\n                        fig = px.box(\n                            df,\n                            x=categorical_cols[0],\n                            y=numeric_cols[0],\n                            title=f\"Box Plot: {numeric_cols[0]} by {categorical_cols[0]}\"\n                        )\n                    else:\n                        # Simple bar chart of first column counts\n                        first_col = df.columns[0]\n                        value_counts = df[first_col].value_counts().head(10)\n                        fig = px.bar(\n                            x=value_counts.index,\n                            y=value_counts.values,\n                            title=f\"Count of {first_col} Values\"\n                        )\n                    \n                    # Improve layout\n                    fig.update_layout(\n                        template=\"plotly_white\",\n                        margin=dict(l=40, r=40, t=60, b=40)\n                    )\n                    \n                    # Convert to base64\n                    buf = io.BytesIO()\n                    fig.write_image(buf, format=\"png\")\n                    img_b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n                    base64_image = f\"data:image/png;base64,{img_b64}\"\n                    \n                    # Create a message about the visualization\n                    viz_description = f\"I've created a visualization of the data.\"\n                    if 'Time worked' in df.columns and 'User' in df.columns:\n                        viz_description += f\" This bar chart shows the total hours worked by each user, which can help identify workload distribution across the team.\"\n                    \n                    # Create an AI message with the visualization description\n                    viz_message = AIMessage(content=f\"{viz_description}\\n\\n{base64_image}\")\n                    \n                    # Get all messages so far\n                    messages = state[\"messages\"]\n                    \n                    # Return the updated messages\n                    return {\n                        \"messages\": messages + [viz_message]\n                    }\n                \n                except Exception as direct_viz_error:\n                    # If direct visualization fails, fall back to the LLM approach\n                    print(f\"Direct visualization failed: {direct_viz_error}. Falling back to LLM.\")\n                    \n                    # Get all messages so far\n                    messages = state[\"messages\"]\n                    # Add a transition message for the visualization phase\n                    transition_message = HumanMessage(content=\"Now, create a visualization of this data.\")\n                    # We invoke the LLM with all messages plus the transition\n                    viz_messages = messages + [transition_message]\n                    # Replace the system message with the visualization system message\n                    viz_messages[0] = SystemMessage(content=self._get_visualization_system_message())\n                    # Invoke the LLM\n                    response = llm_with_tools.invoke(viz_messages)\n                    # Return the updated messages\n                    return {\n                        \"messages\": viz_messages + [response]\n                    }\n            \n            # Define the tools node\n            tools_node = ToolNode(all_tools)\n            \n            # Build the graph\n            graph_builder = StateGraph(State)\n            graph_builder.add_node(\"analysis_agent\", analysis_agent)\n            graph_builder.add_node(\"visualization_agent\", visualization_agent)\n            graph_builder.add_node(\"tools\", tools_node)\n            \n            # Add the edges\n            graph_builder.add_edge(START, \"analysis_agent\")\n            graph_builder.add_edge(\"tools\", \"analysis_agent\")\n            \n            # Add conditional edges: when analysis_agent is done with tools, go to visualization_agent\n            graph_builder.add_conditional_edges(\n                \"analysis_agent\",\n                tools_condition,\n                {\n                    \"tools\": \"tools\",\n                    END: \"visualization_agent\"\n                }\n            )\n            \n            # After visualization_agent is done, terminate\n            graph_builder.add_edge(\"visualization_agent\", END)\n            \n            # Initialize memory\n            memory = MemorySaver()\n            \n            # Compile the graph\n            graph = graph_builder.compile(checkpointer=memory)\n            \n            # Define memory config\n            memory_config = {\"configurable\": {\"thread_id\": \"1\"}}\n            \n            # Create initial messages\n            initial_messages = [\n                SystemMessage(content=self._get_analysis_system_message()),\n                HumanMessage(content=self.input_value or \"Please analyze this CSV file and create a visualization.\")\n            ]\n            \n            # Invoke the graph\n            result = graph.invoke({\"messages\": initial_messages}, memory_config)\n            \n            # Extract all AI responses\n            ai_messages = [msg for msg in result[\"messages\"] if isinstance(msg, AIMessage)]\n            if not ai_messages:\n                return Message(text=\"No response was generated. Please try again.\")\n            \n            # We need both the analysis and visualization responses\n            analysis_response = \"\"\n            visualization_response = \"\"\n            base64_image = None\n            \n            # Extract base64 image from any message\n            for msg in ai_messages:\n                if not base64_image:  # Only get the first image found\n                    import re\n                    base64_match = re.search(r'data:image/png;base64,[A-Za-z0-9+/=]+', msg.content or \"\")\n                    if base64_match:\n                        base64_image = base64_match.group(0)\n            \n            # The last message should be from the visualization agent\n            visualization_response = ai_messages[-1].content or \"\"\n            \n            # Clean up the visualization response (remove the base64 data)\n            clean_viz_response = \"\"\n            if visualization_response:\n                import re\n                clean_viz_response = re.sub(r'data:image/png;base64,[A-Za-z0-9+/=]+', '', visualization_response).strip()\n            \n            # Find the analysis response (should be an earlier AI message)\n            for msg in ai_messages[:-1]:  # Look through all messages except the last one\n                if \"CSV Dataset Analysis\" in (msg.content or \"\"):\n                    analysis_response = msg.content\n                    break\n            \n            # If we couldn't find a specific analysis response, use the first message\n            if not analysis_response and len(ai_messages) > 1:\n                analysis_response = ai_messages[0].content\n            \n            # Format the final response combining both analysis and visualization\n            final_response = \"\"\n            \n            # If we have an analysis response, include it\n            if analysis_response:\n                final_response += f\"{analysis_response}\\n\\n\"\n            \n            # Add the visualization response if we have one\n            if clean_viz_response:\n                final_response += f\"## Data Visualization\\n\\n{clean_viz_response}\"\n            \n            # If we have a base64 image, add it to the response\n            if base64_image:\n                final_response += f\"\\n\\n![CSV Data Visualization]({base64_image})\"\n            else:\n                # If we don't have a base64 image, try to create one directly as a last resort\n                try:\n                    # Read the CSV file\n                    if self.pandas_kwargs:\n                        df = pd.read_csv(csv_path, **self.pandas_kwargs)\n                    else:\n                        df = pd.read_csv(csv_path)\n                    \n                    # Create a simple bar chart\n                    if 'Time worked' in df.columns and 'User' in df.columns:\n                        user_hours = df.groupby('User')['Time worked'].sum().reset_index()\n                        fig = px.bar(\n                            user_hours.sort_values('Time worked', ascending=False),\n                            x='User',\n                            y='Time worked',\n                            title='Total Hours Worked by User'\n                        )\n                    else:\n                        # Use the first column as a fallback\n                        first_col = df.columns[0]\n                        value_counts = df[first_col].value_counts().head(10)\n                        fig = px.bar(\n                            x=value_counts.index,\n                            y=value_counts.values,\n                            title=f\"Top Values of {first_col}\"\n                        )\n                    \n                    # Convert to base64\n                    buf = io.BytesIO()\n                    fig.write_image(buf, format=\"png\")\n                    img_b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n                    base64_image = f\"data:image/png;base64,{img_b64}\"\n                    \n                    # Add to the response\n                    final_response += f\"\\n\\n## Backup Visualization\\n\\n![CSV Data Visualization]({base64_image})\"\n                except Exception as final_viz_error:\n                    final_response += f\"\\n\\n*Note: Unable to generate visualization: {str(final_viz_error)}*\"\n            \n            # Return the formatted response\n            return Message(text=final_response, sender=\"Bot\")\n            \n        except Exception as e:\n            error_msg = f\"Error running the CSV analysis and visualization: {str(e)}\"\n            return Message(text=error_msg, sender=\"Bot\")"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input and extract info from the CSV File.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "An LLM Model Object (It can be found in any LLM Component).",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "pandas_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Pandas Kwargs",
                "dynamic": false,
                "info": "Pandas Kwargs to be passed when reading the CSV.",
                "list": true,
                "list_add_label": "Add More",
                "name": "pandas_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "File Path",
                "dynamic": false,
                "fileTypes": [
                  "csv"
                ],
                "file_path": "1752bbdd-9926-4869-b737-f02b125c1650/8a8d73b3-8d2c-4846-babc-38af98304f02.csv",
                "info": "A CSV File or File Path.",
                "input_types": [
                  "str",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "path",
                "placeholder": "",
                "required": true,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SimpleCSVAgent"
        },
        "id": "SimpleCSVAgent-xm5Xs",
        "measured": {
          "height": 381,
          "width": 320
        },
        "position": {
          "x": 2137.302901460166,
          "y": 3859.546156945641
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-8FDNi",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider. ",
            "display_name": "Language Model",
            "documentation": "",
            "edited": false,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "key": "LanguageModelComponent",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "score": 0.002952328684912448,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_openai import ChatOpenAI\n\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, SecretStrInput, SliderInput\nfrom langflow.schema.dotdict import dotdict\n\n\nclass LanguageModelComponent(LCModelComponent):\n    display_name = \"Language Model\"\n    description = \"Runs a language model given a specified provider. \"\n    icon = \"brain-circuit\"\n    category = \"models\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Model Provider\",\n            options=[\"OpenAI\", \"Anthropic\"],\n            value=\"OpenAI\",\n            info=\"Select the model provider\",\n            real_time_refresh=True,\n            options_metadata=[{\"icon\": \"OpenAI\"}, {\"icon\": \"Anthropic\"}],\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n            info=\"Select the model to use\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"Model Provider API key\",\n            required=False,\n            show=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input text to send to the model\",\n        ),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"A system message that helps set the behavior of the assistant\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=\"Whether to stream the response\",\n            value=False,\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Controls randomness in responses\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        provider = self.provider\n        model_name = self.model_name\n        temperature = self.temperature\n        stream = self.stream\n\n        if provider == \"OpenAI\":\n            if not self.api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n            return ChatOpenAI(\n                model_name=model_name,\n                temperature=temperature,\n                streaming=stream,\n                openai_api_key=self.api_key,\n            )\n        if provider == \"Anthropic\":\n            if not self.api_key:\n                msg = \"Anthropic API key is required when using Anthropic provider\"\n                raise ValueError(msg)\n            return ChatAnthropic(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                anthropic_api_key=self.api_key,\n            )\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"provider\":\n            if field_value == \"OpenAI\":\n                build_config[\"model_name\"][\"options\"] = OPENAI_MODEL_NAMES\n                build_config[\"model_name\"][\"value\"] = OPENAI_MODEL_NAMES[0]\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\n            elif field_value == \"Anthropic\":\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4.1"
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "Select the model provider",
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "OpenAI"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "id": "LanguageModelComponent-8FDNi",
        "measured": {
          "height": 543,
          "width": 320
        },
        "position": {
          "x": 1336.737057003731,
          "y": 5322.8180745130985
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CSVAgent-A8Fx7",
          "node": {
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Construct a CSV agent from a CSV and tools.",
            "display_name": "CSVAgent",
            "documentation": "https://python.langchain.com/docs/modules/agents/toolkits/csv",
            "edited": true,
            "field_order": [
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "llm",
              "path",
              "agent_type",
              "input_value",
              "pandas_kwargs"
            ],
            "frozen": false,
            "icon": "LangChain",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": false,
                "method": "build_agent_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Agent",
                "hidden": true,
                "method": "build_agent",
                "name": "agent",
                "options": null,
                "required_inputs": null,
                "selected": "AgentExecutor",
                "tool_mode": false,
                "types": [
                  "AgentExecutor"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Agent Type",
                "dynamic": false,
                "info": "",
                "name": "agent_type",
                "options": [
                  "zero-shot-react-description",
                  "openai-functions",
                  "openai-tools"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "openai-tools"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent\n\nfrom langflow.base.agents.agent import LCAgentComponent\nfrom langflow.field_typing import AgentExecutor\nfrom langflow.inputs import DropdownInput, FileInput, HandleInput\nfrom langflow.inputs.inputs import DictInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass CSVAgentComponent(LCAgentComponent):\n    display_name = \"CSVAgent\"\n    description = \"Construct a CSV agent from a CSV and tools.\"\n    documentation = \"https://python.langchain.com/docs/modules/agents/toolkits/csv\"\n    name = \"CSVAgent\"\n    icon = \"LangChain\"\n\n    inputs = [\n        *LCAgentComponent._base_inputs,\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"An LLM Model Object (It can be found in any LLM Component).\",\n        ),\n        FileInput(\n            name=\"path\",\n            display_name=\"File Path\",\n            file_types=[\"csv\"],\n            input_types=[\"str\", \"Message\"],\n            required=True,\n            info=\"A CSV File or File Path.\",\n        ),\n        DropdownInput(\n            name=\"agent_type\",\n            display_name=\"Agent Type\",\n            advanced=True,\n            options=[\"zero-shot-react-description\", \"openai-functions\", \"openai-tools\"],\n            value=\"openai-tools\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input and extract info from the CSV File.\",\n            required=True,\n        ),\n        DictInput(\n            name=\"pandas_kwargs\",\n            display_name=\"Pandas Kwargs\",\n            info=\"Pandas Kwargs to be passed to the agent.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response\", method=\"build_agent_response\"),\n        Output(display_name=\"Agent\", name=\"agent\", method=\"build_agent\", hidden=True, tool_mode=False),\n    ]\n\n    def _path(self) -> str:\n        if isinstance(self.path, Message) and isinstance(self.path.text, str):\n            return self.path.text\n        return self.path\n\n    def _create_structured_prompt(self, user_query: str) -> str:\n        # Create the prompt parts separately\n        prompt_intro = f\"User query: {user_query}\\n\\n\"\n        \n        # Define the rest of the prompt as a static string without f-string interpolation\n        prompt_instructions = \"\"\"\nSystem Instructions:  \nYour response **MUST** consist of **TWO** distinct parts:\n\n1. **ANSWER:**  \n   - Parse the user's request to determine **which entity** (e.g. project, customer, user, contract) and **which metric** (e.g. total hours, average time, count) they want from **report.csv**.  \n   - Compute that metric on the fly and state the result in a **short, human-readable sentence** (entity name, metric value, and any top-level insight).\n   - Include a brief suggestion for the most appropriate visualization type for this data (bar, line, pie, or scatter).\n\n2. **JSON_DATA:**  \n   - Immediately after your ANSWER, output a JSON object under the key `\"JSON_DATA\":` that follows this exact schema:\n\nThe JSON must have this structure:\n- \"plot_type\": One of: \"bar\", \"line\", \"pie\", or \"scatter\"\n- \"data\": An array of data objects, where each object has:\n  - \"type\": Same as plot_type\n  - For bar/line/scatter: \"x\" and \"y\" arrays with your data\n  - For pie charts: \"labels\" and \"values\" arrays\n  - Optional \"name\" for the data series\n  - Optional \"marker\" object with \"color\" and \"size\"\n  - Optional \"line\" object with \"color\" and \"width\"\n  - Optional \"mode\" (for line/scatter): \"lines\", \"markers\", or \"lines+markers\"\n  - Optional \"orientation\" (for bar): \"v\" or \"h\"\n- \"layout\": An object containing:\n  - \"title\": Chart title as string\n  - \"showlegend\": true or false\n  - \"xaxis\": Object with \"title\" property\n  - \"yaxis\": Object with \"title\" property\n  - Optional \"barmode\" for multi-series bar charts\n\nExample of valid JSON structure (replace with actual data):\n```\n{\n  \"plot_type\": \"bar\",\n  \"data\": [\n    {\n      \"type\": \"bar\",\n      \"x\": [\"Category A\", \"Category B\", \"Category C\"],\n      \"y\": [20, 35, 15],\n      \"name\": \"Series 1\",\n      \"marker\": {\n        \"color\": \"blue\"\n      }\n    }\n  ],\n  \"layout\": {\n    \"title\": \"Sample Bar Chart\",\n    \"showlegend\": true,\n    \"xaxis\": {\n      \"title\": \"Categories\"\n    },\n    \"yaxis\": {\n      \"title\": \"Values\"\n    }\n  }\n}\n```\n\nNote: \n- Choose the most appropriate plot_type based on the data and query.\n- For bar/line/scatter charts, use \"x\" and \"y\" arrays.\n- For pie charts, use \"labels\" and \"values\" arrays instead.\n- The \"data\" array can contain multiple traces for multi-series visualizations.\n- Make sure all required fields for the chosen plot type are included.\n- Ensure the JSON is **well-formed**, **properly indented**, and follows the schema exactly.\n- The JSON should contain **aggregated statistics** from report.csv that answer the user's query.\n- Include any relevant **breakdowns** by secondary dimensions (e.g., by date, contract, task).\n- Normalize strings for consistent categories and ensure numerical values are appropriate types.\n\nRemember: Your ANSWER should provide the key insight in natural language, while the JSON_DATA should contain all the structured data needed for visualization.\n\"\"\"\n        \n        # Combine the parts\n        return prompt_intro + prompt_instructions\n\n    def build_agent_response(self) -> Message:\n        agent_kwargs = {\n            \"verbose\": self.verbose,\n            \"allow_dangerous_code\": True,\n        }\n\n        agent_csv = create_csv_agent(\n            llm=self.llm,\n            path=self._path(),\n            agent_type=self.agent_type,\n            handle_parsing_errors=self.handle_parsing_errors,\n            pandas_kwargs=self.pandas_kwargs,\n            **agent_kwargs,\n        )\n        \n        # Structure the prompt with the user's query\n        structured_prompt = self._create_structured_prompt(self.input_value)\n        \n        # Pass the structured prompt to the agent\n        result = agent_csv.invoke({\"input\": structured_prompt})\n        return Message(text=str(result[\"output\"]))\n\n    def build_agent(self) -> AgentExecutor:\n        agent_kwargs = {\n            \"verbose\": self.verbose,\n            \"allow_dangerous_code\": True,\n        }\n\n        agent_csv = create_csv_agent(\n            llm=self.llm,\n            path=self._path(),\n            agent_type=self.agent_type,\n            handle_parsing_errors=self.handle_parsing_errors,\n            pandas_kwargs=self.pandas_kwargs,\n            **agent_kwargs,\n        )\n\n        self.status = Message(text=str(agent_csv))\n\n        return agent_csv"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input and extract info from the CSV File.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "An LLM Model Object (It can be found in any LLM Component).",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "pandas_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Pandas Kwargs",
                "dynamic": false,
                "info": "Pandas Kwargs to be passed to the agent.",
                "list": true,
                "list_add_label": "Add More",
                "name": "pandas_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "File Path",
                "dynamic": false,
                "fileTypes": [
                  "csv"
                ],
                "file_path": "1752bbdd-9926-4869-b737-f02b125c1650/8a8d73b3-8d2c-4846-babc-38af98304f02.csv",
                "info": "A CSV File or File Path.",
                "input_types": [
                  "str",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "path",
                "placeholder": "",
                "required": true,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CSVAgent"
        },
        "id": "CSVAgent-A8Fx7",
        "measured": {
          "height": 361,
          "width": 320
        },
        "position": {
          "x": 1962.8760722672482,
          "y": 5739.271781652934
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-8jyTp",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": false,
                "method": "message_response",
                "name": "response",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": false,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks. You will receive information with a json structure. You need to create a plotly chart using our Python REPL tool. Generate code that best adjust to the json structure. Save the image and return it in our message.\nDO NOT USE Matplotlib, USE plotly.\nYou need to return the image so we can display it in the chat. Use this as reference:\n```\n# Create a Plotly visualization based on the agent's response\n        fig, chart_title = self._create_plotly_visualization(df, text_response)\n        \n        # Save the image and encode it to base64\n        img_bytes = fig.to_image(format=\"png\")\n        img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n        base64_url = f\"data:image/png;base64,{img_base64}\"\n        \n        # Build the response message with both the text and the embedded image\n        markdown_text = f\"{text_response}\\n\\n### {chart_title}\\n\\n![Plotly Visualization]({base64_url})\"\n        \n        return Message(text=markdown_text, sender=\"Bot\")\n\n```\n"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "id": "Agent-8jyTp",
        "measured": {
          "height": 621,
          "width": 320
        },
        "position": {
          "x": 2714.404259030053,
          "y": 4165.960490099519
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonREPLComponent-B3m0U",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "tools",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "A Python code executor that lets you run Python code with specific imported modules. Remember to always use print() to see your results. Example: print(df.head())",
            "display_name": "Python REPL",
            "documentation": "",
            "edited": false,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "Python",
            "key": "PythonREPLComponent",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003461035063578755,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import importlib\n\nfrom langchain_experimental.utilities import PythonREPL\n\nfrom langflow.custom import Component\nfrom langflow.io import CodeInput, Output, StrInput\nfrom langflow.schema import Data\n\n\nclass PythonREPLComponent(Component):\n    display_name = \"Python REPL\"\n    description = (\n        \"A Python code executor that lets you run Python code with specific imported modules. \"\n        \"Remember to always use print() to see your results. Example: print(df.head())\"\n    )\n    icon = \"Python\"\n\n    inputs = [\n        StrInput(\n            name=\"global_imports\",\n            display_name=\"Global Imports\",\n            info=\"A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.\",\n            value=\"math,pandas\",\n            required=True,\n        ),\n        CodeInput(\n            name=\"python_code\",\n            display_name=\"Python Code\",\n            info=\"The Python code to execute. Only modules specified in Global Imports can be used.\",\n            value=\"print('Hello, World!')\",\n            tool_mode=True,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=Data,\n            method=\"run_python_repl\",\n        ),\n    ]\n\n    def get_globals(self, global_imports: str | list[str]) -> dict:\n        \"\"\"Create a globals dictionary with only the specified allowed imports.\"\"\"\n        global_dict = {}\n\n        try:\n            if isinstance(global_imports, str):\n                modules = [module.strip() for module in global_imports.split(\",\")]\n            elif isinstance(global_imports, list):\n                modules = global_imports\n            else:\n                msg = \"global_imports must be either a string or a list\"\n                raise TypeError(msg)\n\n            for module in modules:\n                try:\n                    imported_module = importlib.import_module(module)\n                    global_dict[imported_module.__name__] = imported_module\n                except ImportError as e:\n                    msg = f\"Could not import module {module}: {e!s}\"\n                    raise ImportError(msg) from e\n\n        except Exception as e:\n            self.log(f\"Error in global imports: {e!s}\")\n            raise\n        else:\n            self.log(f\"Successfully imported modules: {list(global_dict.keys())}\")\n            return global_dict\n\n    def run_python_repl(self) -> Data:\n        try:\n            globals_ = self.get_globals(self.global_imports)\n            python_repl = PythonREPL(_globals=globals_)\n            result = python_repl.run(self.python_code)\n            result = result.strip() if result else \"\"\n\n            self.log(\"Code execution completed successfully\")\n            return Data(data={\"result\": result})\n\n        except ImportError as e:\n            error_message = f\"Import Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except SyntaxError as e:\n            error_message = f\"Syntax Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except (NameError, TypeError, ValueError) as e:\n            error_message = f\"Error during execution: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n    def build(self):\n        return self.run_python_repl\n"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Global Imports",
                "dynamic": false,
                "info": "A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas, plotly"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python Code",
                "dynamic": false,
                "info": "The Python code to execute. Only modules specified in Global Imports can be used.",
                "list": false,
                "list_add_label": "Add More",
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "print('Hello, World!')"
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "python_code": {
                        "description": "The Python code to execute. Only modules specified in Global Imports can be used.",
                        "title": "Python Code",
                        "type": "string"
                      }
                    },
                    "description": "PythonREPLComponent. run_python_repl - A Python code executor that lets you run Python code with specific imported modules. Remember to always use print() to see your results. Example: print(df.head())",
                    "display_description": "PythonREPLComponent. run_python_repl - A Python code executor that lets you run Python code with specific imported modules. Remember to always use print() to see your results. Example: print(df.head())",
                    "display_name": "run_python_repl",
                    "name": "run_python_repl",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "run_python_repl"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "PythonREPLComponent"
        },
        "id": "PythonREPLComponent-B3m0U",
        "measured": {
          "height": 369,
          "width": 320
        },
        "position": {
          "x": 1609.5754906136708,
          "y": 4309.504579642002
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "StructuredOutput-ktP0P",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Transforms LLM responses into **structured data formats**. Ideal for extracting specific information or creating consistent outputs.",
            "display_name": "Structured Output",
            "documentation": "",
            "edited": true,
            "field_order": [
              "llm",
              "input_value",
              "output_type",
              "custom_schema_system_prompt",
              "schema_name",
              "output_schema",
              "plot_type",
              "plot_schema_instructions",
              "multiple"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Structured Output",
                "hidden": false,
                "method": "build_structured_output",
                "name": "structured_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "hidden": null,
                "method": "as_dataframe",
                "name": "structured_output_dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Visualization Data",
                "hidden": null,
                "method": "get_visualization_data",
                "name": "visualization_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pydantic import BaseModel, Field, create_model\nfrom trustcall import create_extractor\nimport json\nfrom typing import List, Union, Dict, Any, Optional\n\nfrom langflow.base.models.chat_result import get_chat_result\nfrom langflow.custom import Component\nfrom langflow.helpers.base_model import build_model_from_schema\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TableInput,\n    DropdownInput,\n)\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.table import EditMode\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = (\n        \"Transforms LLM responses into **structured data formats**. Ideal for extracting specific information \"\n        \"or creating consistent outputs.\"\n    )\n    name = \"StructuredOutput\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Message\",\n            info=\"The input message to the language model.\",\n            tool_mode=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            info=\"Select the type of structured output to generate\",\n            options=[\"Custom Schema\", \"Plotly Visualization\"],\n            value=\"Custom Schema\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"custom_schema_system_prompt\",\n            display_name=\"Custom Schema Instructions\",\n            info=\"The instructions to the language model for formatting the custom schema output.\",\n            value=(\n                \"You are an AI system designed to extract structured information from unstructured text.\"\n                \"Given the input_text, return a JSON object with predefined keys based on the expected structure.\"\n                \"Extract values accurately and format them according to the specified type \"\n                \"(e.g., string, integer, float, date).\"\n                \"If a value is missing or cannot be determined, return a default \"\n                \"(e.g., null, 0, or 'N/A').\"\n                \"If multiple instances of the expected structure exist within the input_text, \"\n                \"stream each as a separate JSON object.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Custom Output Schema\",\n            info=\"Define the structure and data types for the model's output when using Custom Schema.\",\n            required=False,\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\n                        \"Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).\"\n                    ),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"list\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"Multiple\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[\n                {\n                    \"name\": \"field\",\n                    \"description\": \"description of field\",\n                    \"type\": \"str\",\n                    \"multiple\": \"False\",\n                }\n            ],\n        ),\n        DropdownInput(\n            name=\"plot_type\",\n            display_name=\"Plot Type\",\n            info=\"The type of plot to generate when using Plotly Visualization\",\n            options=[\"bar\", \"line\", \"pie\", \"scatter\"],\n            value=\"bar\",\n            required=False,\n            advanced=False,\n        ),\n        MultilineInput(\n            name=\"plot_schema_instructions\",\n            display_name=\"Plot Schema Instructions\",\n            info=\"Instructions for the language model on how to format the plot data when using Plotly Visualization.\",\n            value=(\n                \"You are an AI system designed to generate Plotly visualization data from unstructured text.\\n\\n\"\n                \"Given the user's input, create a JSON object following this structure:\\n\\n\"\n                \"{\\n\"\n                '  \"plot_type\": \"bar|line|pie|scatter\",\\n'\n                '  \"data\": [\\n'\n                \"    {\\n\"\n                '      \"type\": \"bar|line|pie|scatter\",\\n'\n                '      \"x\": [array of x values],\\n'\n                '      \"y\": [array of y values],\\n'\n                '      \"labels\": [array of labels for pie chart],\\n'\n                '      \"values\": [array of values for pie chart],\\n'\n                '      \"name\": \"optional trace name\",\\n'\n                '      \"marker\": {\"color\": \"color value\", \"size\": number}\\n'\n                \"    }\\n\"\n                \"  ],\\n\"\n                '  \"layout\": {\\n'\n                '    \"title\": \"Plot Title\",\\n'\n                '    \"xaxis\": {\"title\": \"X Axis Title\"},\\n'\n                '    \"yaxis\": {\"title\": \"Y Axis Title\"}\\n'\n                \"  }\\n\"\n                \"}\\n\\n\"\n                \"Ensure you use the most appropriate plot type (bar, line, pie, or scatter) based on the data.\"\n                \"For pie charts, use 'labels' and 'values' instead of 'x' and 'y'.\"\n                \"Validate your JSON to ensure it follows the proper structure.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"multiple\",\n            advanced=True,\n            display_name=\"Generate Multiple\",\n            info=\"[Deprecated] Always set to True\",\n            value=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"structured_output\",\n            display_name=\"Structured Output\",\n            method=\"build_structured_output\",\n        ),\n        Output(\n            name=\"structured_output_dataframe\",\n            display_name=\"DataFrame\",\n            method=\"as_dataframe\",\n        ),\n        Output(\n            name=\"visualization_data\",\n            display_name=\"Visualization Data\",\n            method=\"get_visualization_data\",\n        ),\n    ]\n\n    def build_structured_output_base(self) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        if self.output_type == \"Custom Schema\":\n            print(\"----------->build_structured_output_base: CustomSchema\")\n            return self._build_plot_schema_output()\n        elif self.output_type == \"Plotly Visualization\":\n            print(\"----------->build_structured_output_base: Plotly Visualization\")\n            return self._build_plot_schema_output()\n        else:\n            print(\"----------->build_structured_output_base: Unsupported type\")\n            msg = f\"Unsupported output type: {self.output_type}\"\n            raise ValueError(msg)\n\n    def _build_custom_schema_output(self) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        schema_name = self.schema_name or \"OutputModel\"\n\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty for Custom Schema output type\"\n            raise ValueError(msg)\n\n        output_model_ = build_model_from_schema(self.output_schema)\n\n        output_model = create_model(\n            schema_name,\n            __doc__=f\"A list of {schema_name}.\",\n            objects=(list[output_model_], Field(description=f\"A list of {schema_name}.\")),  # type: ignore[valid-type]\n        )\n\n        try:\n            llm_with_structured_output = create_extractor(self.llm, tools=[output_model])\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        \n        # Use custom_schema_system_prompt if it exists, otherwise use a default prompt\n        system_prompt = self.custom_schema_system_prompt\n        if not system_prompt:\n            system_prompt = (\n                \"You are an AI system designed to extract structured information from unstructured text.\"\n                \"Given the input_text, return a JSON object with predefined keys based on the expected structure.\"\n                \"Extract values accurately and format them according to the specified type.\"\n            )\n            \n        result = get_chat_result(\n            runnable=llm_with_structured_output,\n            system_message=system_prompt,\n            input_value=self.input_value,\n            config=config_dict,\n        )\n        if isinstance(result, BaseModel):\n            result = result.model_dump()\n        if responses := result.get(\"responses\"):\n            result = responses[0].model_dump()\n        if result and \"objects\" in result:\n            return result[\"objects\"]\n\n        return result\n\n    def _build_plot_schema_output(self) -> Dict[str, Any]:\n        class PlotDataTypes(BaseModel):\n            class PlotDataItem(BaseModel):\n                type: str\n                x: Optional[List[Union[str, int, float]]] = None  \n                y: Optional[List[Union[str, int, float]]] = None\n                labels: Optional[List[str]] = None\n                values: Optional[List[float]] = None\n                name: Optional[str] = None\n                mode: Optional[str] = None\n                marker: Optional[Dict[str, Any]] = None\n                line: Optional[Dict[str, Any]] = None\n                orientation: Optional[str] = None\n\n            class PlotLayout(BaseModel):\n                title: str\n                showlegend: Optional[bool] = None\n                width: Optional[int] = None\n                height: Optional[int] = None\n                xaxis: Optional[Dict[str, Any]] = None\n                yaxis: Optional[Dict[str, Any]] = None\n                barmode: Optional[str] = None\n                paper_bgcolor: Optional[str] = None\n                plot_bgcolor: Optional[str] = None\n\n            plot_type: str\n            data: List[PlotDataItem]\n            layout: PlotLayout\n\n        # Create the visualization model\n        visualization_model = create_model(\n            \"PlotlyVisualization\",\n            __doc__=\"Data for creating a Plotly visualization.\",\n            visualization=(PlotDataTypes, Field(description=\"Plotly visualization data\")),\n        )\n\n        try:\n            system_prompt = self.plot_schema_instructions\n            if not system_prompt:\n                system_prompt = (\n                    \"You are an AI system designed to generate Plotly visualization data from unstructured text.\\n\\n\"\n                    f\"Generate a {self.plot_type} chart based on the data described in the input.\"\n                )\n\n            llm_with_structured_output = create_extractor(self.llm, tools=[visualization_model])\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        \n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        \n        result = get_chat_result(\n            runnable=llm_with_structured_output,\n            system_message=system_prompt,\n            input_value=self.input_value,\n            config=config_dict,\n        )\n        \n        if isinstance(result, BaseModel):\n            result = result.model_dump()\n        if responses := result.get(\"responses\"):\n            result = responses[0].model_dump()\n        if result and \"visualization\" in result:\n            return result[\"visualization\"]\n            \n        return result\n\n    def build_structured_output(self) -> Data:\n        \n        output = self.build_structured_output_base()\n        print(f\"------------------>from build_structured_output{output}\")\n        return Data(text_key=\"results\", data={\"results\": output})\n\n    def as_dataframe(self) -> DataFrame:\n        output = self.build_structured_output_base()\n        if isinstance(output, list):\n            return DataFrame(data=output)\n        return DataFrame(data=[output])\n    \n    def get_visualization_data(self) -> Data:\n        \"\"\"Return the visualization data in a format that can be used by visualization components.\"\"\"\n        if self.output_type != \"Plotly Visualization\":\n            return Data(text_key=\"message\", data={\"message\": \"Visualization data is only available for Plotly Visualization output type\"})\n        \n        output = self.build_structured_output_base()\n        # Format specifically for visualization components\n        return Data(text_key=\"visualization\", data={\"visualization\": output})"
              },
              "custom_schema_system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Custom Schema Instructions",
                "dynamic": false,
                "info": "The instructions to the language model for formatting the custom schema output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "custom_schema_system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI system designed to extract structured information from unstructured text.Given the input_text, return a JSON object with predefined keys based on the expected structure.Extract values accurately and format them according to the specified type (e.g., string, integer, float, date).If a value is missing or cannot be determined, return a default (e.g., null, 0, or 'N/A').If multiple instances of the expected structure exist within the input_text, stream each as a separate JSON object."
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The input message to the language model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "The language model to use to generate the structured output.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "multiple": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Generate Multiple",
                "dynamic": false,
                "info": "[Deprecated] Always set to True",
                "list": false,
                "list_add_label": "Add More",
                "name": "multiple",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Custom Output Schema",
                "dynamic": false,
                "info": "Define the structure and data types for the model's output when using Custom Schema.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "field",
                      "description": "Specify the name of the output field.",
                      "disable_edit": false,
                      "display_name": "Name",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "name",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "description of field",
                      "description": "Describe the purpose of the output field.",
                      "disable_edit": false,
                      "display_name": "Description",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "description",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "str",
                      "description": "Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).",
                      "disable_edit": false,
                      "display_name": "Type",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "type",
                      "options": [
                        "str",
                        "int",
                        "float",
                        "bool",
                        "list",
                        "dict"
                      ],
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": false,
                      "description": "Set to True if this output field should be a list of the specified type.",
                      "disable_edit": false,
                      "display_name": "Multiple",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "boolean",
                      "hidden": false,
                      "name": "multiple",
                      "sortable": true,
                      "type": "boolean"
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "description": "description of field",
                    "multiple": "False",
                    "name": "field",
                    "type": "str"
                  }
                ]
              },
              "output_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the type of structured output to generate",
                "name": "output_type",
                "options": [
                  "Custom Schema",
                  "Plotly Visualization"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Custom Schema"
              },
              "plot_schema_instructions": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Plot Schema Instructions",
                "dynamic": false,
                "info": "Instructions for the language model on how to format the plot data when using Plotly Visualization.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "plot_schema_instructions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI system designed to generate Plotly visualization data from unstructured text.\n\nGiven the user's input, create a JSON object following this structure:\n\n{\n  \"plot_type\": \"bar|line|pie|scatter\",\n  \"data\": [\n    {\n      \"type\": \"bar|line|pie|scatter\",\n      \"x\": [array of x values],\n      \"y\": [array of y values],\n      \"labels\": [array of labels for pie chart],\n      \"values\": [array of values for pie chart],\n      \"name\": \"optional trace name\",\n      \"marker\": {\"color\": \"color value\", \"size\": number}\n    }\n  ],\n  \"layout\": {\n    \"title\": \"Plot Title\",\n    \"xaxis\": {\"title\": \"X Axis Title\"},\n    \"yaxis\": {\"title\": \"Y Axis Title\"}\n  }\n}\n\nEnsure you use the most appropriate plot type (bar, line, pie, or scatter) based on the data.For pie charts, use 'labels' and 'values' instead of 'x' and 'y'.Validate your JSON to ensure it follows the proper structure."
              },
              "plot_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Plot Type",
                "dynamic": false,
                "info": "The type of plot to generate when using Plotly Visualization",
                "name": "plot_type",
                "options": [
                  "bar",
                  "line",
                  "pie",
                  "scatter"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "bar"
              },
              "schema_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Schema Name",
                "dynamic": false,
                "info": "Provide a name for the output data schema.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "schema_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "StructuredOutput"
        },
        "id": "StructuredOutput-ktP0P",
        "measured": {
          "height": 821,
          "width": 320
        },
        "position": {
          "x": 2388.6337630581324,
          "y": 4997.821971893266
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PlotlyVisualizerComponent-02C8e",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates charts from structured JSON data using our Plotly schema",
            "display_name": "Plotly Visualizer",
            "documentation": "",
            "edited": true,
            "field_order": [
              "structured_data",
              "customize_colors"
            ],
            "frozen": false,
            "icon": "chart-bar",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "hidden": false,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output, HandleInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nimport plotly.graph_objects as go\nimport io\nimport base64\nimport tempfile\nimport os\nimport json\nimport re\nimport ast\n\nclass PlotlyVisualizerComponent(Component):\n    display_name = \"Plotly Visualizer\"\n    description = \"Creates charts from structured JSON data using our Plotly schema\"\n    icon = \"chart-bar\"\n    name = \"PlotlyVisualizerComponent\"\n\n    inputs = [\n        HandleInput(\n            name=\"structured_data\",\n            display_name=\"Structured Data\",\n            info=\"The structured data from a StructuredOutput component or CSV agent response\",\n            input_types=[\"Data\", \"Message\", \"dict\", \"str\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"customize_colors\",\n            display_name=\"Customize Colors\",\n            info=\"Optional comma-separated colors to use (e.g., 'blue,red,green')\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def _extract_json_from_message(self, text):\n        \"\"\"Extract JSON data from text that might contain ANSWER and JSON_DATA sections.\"\"\"\n        if not text:\n            return None\n            \n        # Print the text for debugging\n        print(f\"Extracting JSON from text: {text[:100]}...\") # Show first 100 chars only\n        \n        # First try to directly extract from a Data object with results that contain JSON_DATA\n        if \"JSON_DATA:\" in text:\n            print(\"Found JSON_DATA marker in text\")\n            \n            # Enhanced pattern for JSON_DATA with backticks - this better handles multi-line JSON with proper escaping\n            json_data_pattern = r'JSON_DATA:\\s*```(?:json)?\\s*([\\s\\S]*?)\\s*```'\n            match = re.search(json_data_pattern, text, re.DOTALL)\n            \n            if match:\n                json_str = match.group(1).strip()\n                print(f\"Found JSON_DATA block with backticks, extracting: {json_str[:100]}...\")\n                try:\n                    return json.loads(json_str)\n                except json.JSONDecodeError as e:\n                    print(f\"Failed to parse JSON_DATA block with backticks: {e}\")\n            \n            # Check for JSON_DATA: followed by a JSON object (without code blocks)\n            json_data_pattern2 = r'JSON_DATA:\\s*(\\{[\\s\\S]*?\\})'\n            match = re.search(json_data_pattern2, text, re.DOTALL)\n            \n            if match:\n                json_str = match.group(1).strip()\n                print(f\"Found JSON_DATA block without backticks: {json_str[:100]}...\")\n                try:\n                    return json.loads(json_str)\n                except json.JSONDecodeError as e:\n                    print(f\"Failed to parse JSON_DATA block without backticks: {e}\")\n                    \n            # Try a more general extraction for any JSON object after JSON_DATA:\n            try:\n                # Split the text by JSON_DATA: and take the part after it\n                parts = text.split(\"JSON_DATA:\", 1)\n                if len(parts) > 1:\n                    json_part = parts[1].strip()\n                    # Remove leading backticks if present\n                    if json_part.startswith(\"```\"):\n                        json_part = json_part.split(\"```\", 2)[1]\n                        if json_part.startswith(\"json\"):\n                            json_part = json_part[4:].strip()\n                    # Remove trailing backticks if present\n                    if \"```\" in json_part:\n                        json_part = json_part.split(\"```\")[0].strip()\n                    print(f\"Attempting to parse extracted JSON part: {json_part[:100]}...\")\n                    return json.loads(json_part)\n            except Exception as e:\n                print(f\"Error in general JSON extraction: {str(e)}\")\n        \n        # Check if the whole text is valid JSON\n        try:\n            return json.loads(text)\n        except json.JSONDecodeError:\n            pass\n        \n        # Look for any JSON object in the text\n        json_pattern = r'(\\{[\\s\\S]*?\\})'\n        match = re.search(json_pattern, text, re.DOTALL)\n        \n        if match:\n            json_str = match.group(1)\n            try:\n                return json.loads(json_str)\n            except json.JSONDecodeError:\n                pass\n                \n        return None\n\n    def _parse_array_value(self, value_str):\n        \"\"\"Parse a string that contains an array representation.\"\"\"\n        if not value_str or not isinstance(value_str, str):\n            return []\n            \n        # First try normal JSON parsing\n        try:\n            return json.loads(value_str)\n        except json.JSONDecodeError:\n            pass\n            \n        # Try using ast.literal_eval for safer evaluation\n        try:\n            return ast.literal_eval(value_str)\n        except (SyntaxError, ValueError):\n            pass\n            \n        # Try manually parsing comma-separated values enclosed in brackets\n        if value_str.startswith('[') and value_str.endswith(']'):\n            inner_str = value_str[1:-1].strip()\n            if inner_str:\n                # Split by comma but handle quoted strings properly\n                items = []\n                current_item = \"\"\n                in_quotes = False\n                \n                for char in inner_str:\n                    if char == '\"' or char == \"'\":\n                        in_quotes = not in_quotes\n                        current_item += char\n                    elif char == ',' and not in_quotes:\n                        items.append(current_item.strip())\n                        current_item = \"\"\n                    else:\n                        current_item += char\n                        \n                # Add the last item\n                if current_item:\n                    items.append(current_item.strip())\n                \n                # Convert to appropriate types\n                processed_items = []\n                for item in items:\n                    item = item.strip()\n                    \n                    # Remove quotes for strings\n                    if (item.startswith('\"') and item.endswith('\"')) or (item.startswith(\"'\") and item.endswith(\"'\")):\n                        processed_items.append(item[1:-1])\n                    else:\n                        # Try to convert to number\n                        try:\n                            if '.' in item:\n                                processed_items.append(float(item))\n                            else:\n                                processed_items.append(int(item))\n                        except ValueError:\n                            # Keep as string if not a number\n                            processed_items.append(item)\n                \n                return processed_items\n                \n        # Simple comma-separated values as fallback\n        return [item.strip() for item in value_str.split(',')]\n\n    def _process_structured_output_data(self, data):\n        \"\"\"Process data from the StructuredOutput component.\"\"\"\n        print(f\"Processing structured output data: {data}\")\n        \n        # Check if this is the format from the StructuredOutput component\n        if isinstance(data, dict):\n            # Check for error message from StructuredOutput\n            if \"message\" in data and \"Visualization data is only available for Plotly Visualization output type\" in data.get(\"message\", \"\"):\n                return None\n                \n            # Check for \"results\" key (from build_structured_output)\n            if \"results\" in data:\n                results = data[\"results\"]\n                \n                # Check for the specific format we're seeing: flat list of alternating field objects\n                if isinstance(results, list) and len(results) > 0 and all(isinstance(item, dict) and \"field\" in item for item in results):\n                    # Try to determine if this is the alternating x/y values pattern\n                    # (like we're seeing with project names followed by hours)\n                    if len(results) >= 4:  # Need at least 2 pairs of x/y values\n                        # Assume alternating pattern of labels and values\n                        x_values = []\n                        y_values = []\n                        \n                        for i in range(0, len(results), 2):\n                            if i + 1 < len(results):\n                                x_field = results[i].get(\"field\", \"\")\n                                y_field = results[i + 1].get(\"field\", \"\")\n                                \n                                # Try to convert y to a number\n                                try:\n                                    y_value = float(y_field)\n                                    x_values.append(x_field)\n                                    y_values.append(y_value)\n                                except (ValueError, TypeError):\n                                    # If we can't convert to float, this might not be the right pattern\n                                    continue\n                        \n                        # If we successfully extracted x/y pairs, create visualization\n                        if len(x_values) > 0 and len(y_values) > 0:\n                            # Construct a proper visualization object\n                            visualization = {\n                                \"plot_type\": \"bar\",\n                                \"data\": [{\n                                    \"type\": \"bar\",\n                                    \"x\": x_values,\n                                    \"y\": y_values,\n                                    \"name\": \"Total\",\n                                    \"marker\": {\"color\": \"steelblue\"}\n                                }],\n                                \"layout\": {\n                                    \"title\": \"Data Visualization\",\n                                    \"showlegend\": False,\n                                    \"xaxis\": {\"title\": \"Categories\"},\n                                    \"yaxis\": {\"title\": \"Values\"}\n                                }\n                            }\n                            \n                            print(f\"Constructed visualization from alternating fields: {visualization}\")\n                            return visualization\n                    \n                    # If alternating pattern didn't work, check for our previous format\n                    plot_data = {}\n                    x_values = []\n                    y_values = []\n                    title = \"Chart\"\n                    plot_type = \"bar\"\n                    mode = \"markers\"\n                    line_color = \"blue\"\n                    line_width = 2\n                    marker_color = \"steelblue\"\n                    marker_size = 6\n                    x_axis_title = \"Categories\"\n                    y_axis_title = \"Values\"\n                    \n                    for item in results:\n                        field_value = item.get(\"field\", \"\")\n                        if isinstance(field_value, str):\n                            # Extract the plot type\n                            if field_value.startswith(\"plot_type:\"):\n                                plot_type = field_value.split(\":\", 1)[1].strip()\n                            \n                            # Handle different variations of x field names\n                            elif any(field_value.startswith(prefix) for prefix in [\"x:\", \"x (\", \"x values:\"]):\n                                try:\n                                    # Extract the array part after the colon\n                                    x_str = re.split(r':|:|\\)\\s*:', field_value, 1)[1].strip()\n                                    x_values = self._parse_array_value(x_str)\n                                    print(f\"Parsed x values: {x_values}\")\n                                except Exception as e:\n                                    print(f\"Error parsing x values: {e}\")\n                            \n                            # Handle different variations of y field names\n                            elif any(field_value.startswith(prefix) for prefix in [\"y:\", \"y (\", \"y values:\"]):\n                                try:\n                                    # Extract the array part after the colon\n                                    y_str = re.split(r':|:|\\)\\s*:', field_value, 1)[1].strip()\n                                    y_values = self._parse_array_value(y_str)\n                                    print(f\"Parsed y values: {y_values}\")\n                                except Exception as e:\n                                    print(f\"Error parsing y values: {e}\")\n                            \n                            # Extract title\n                            elif field_value.startswith(\"title:\"):\n                                title = field_value.split(\":\", 1)[1].strip()\n                            \n                            # Extract mode\n                            elif field_value.startswith(\"mode:\"):\n                                mode = field_value.split(\":\", 1)[1].strip()\n                            \n                            # Extract line properties\n                            elif \"line color:\" in field_value.lower():\n                                line_color = field_value.split(\":\", 1)[1].strip()\n                            elif \"line width:\" in field_value.lower():\n                                try:\n                                    line_width = float(field_value.split(\":\", 1)[1].strip())\n                                except ValueError:\n                                    pass\n                            \n                            # Extract marker properties\n                            elif \"marker color:\" in field_value.lower():\n                                marker_color = field_value.split(\":\", 1)[1].strip()\n                            elif \"marker size:\" in field_value.lower():\n                                try:\n                                    marker_size = float(field_value.split(\":\", 1)[1].strip())\n                                except ValueError:\n                                    pass\n                            \n                            # Extract axis titles\n                            elif \"x axis title:\" in field_value.lower():\n                                x_axis_title = field_value.split(\":\", 1)[1].strip()\n                            elif \"y axis title:\" in field_value.lower():\n                                y_axis_title = field_value.split(\":\", 1)[1].strip()\n                    \n                    # Configure marker and line based on extracted properties\n                    marker = {\"color\": marker_color, \"size\": marker_size}\n                    line = {\"color\": line_color, \"width\": line_width}\n                    \n                    if plot_type == \"line\" and not mode:\n                        mode = \"lines+markers\"\n                    \n                    # Construct a proper visualization object\n                    visualization = {\n                        \"plot_type\": plot_type,\n                        \"data\": [{\n                            \"type\": plot_type,\n                            \"x\": x_values,\n                            \"y\": y_values,\n                            \"name\": title,\n                            \"marker\": marker,\n                            \"line\": line,\n                            \"mode\": mode\n                        }],\n                        \"layout\": {\n                            \"title\": title,\n                            \"showlegend\": False,\n                            \"xaxis\": {\"title\": x_axis_title},\n                            \"yaxis\": {\"title\": y_axis_title}\n                        }\n                    }\n                    \n                    print(f\"Constructed visualization from fields: {visualization}\")\n                    return visualization\n                \n                # Sometimes results might be a list of visualization objects\n                elif isinstance(results, list) and len(results) > 0:\n                    # Take the first item if it's a list\n                    if isinstance(results[0], dict) and (\"plot_type\" in results[0] or \"data\" in results[0]):\n                        return results[0]\n                \n                return results\n            \n            # Check for \"visualization\" key (from get_visualization_data)\n            if \"visualization\" in data:\n                return data[\"visualization\"]\n        \n        # If it's already a list, it might be a list of plot data\n        if isinstance(data, list) and len(data) > 0:\n            # Check if the first item looks like a visualization object\n            first_item = data[0]\n            if isinstance(first_item, dict) and (\"plot_type\" in first_item or \"data\" in first_item):\n                return first_item\n            \n        # If not in a known format, return as is\n        return data\n\n    def build_output(self) -> Message:\n        # Process the input data\n        data_source = self.structured_data\n        json_data = None\n        \n        # For debugging\n        print(f\"Input data: {data_source}\")\n        print(f\"Input data type: {type(data_source)}\")\n        if isinstance(data_source, Message):\n            print(f\"Message text sample: {data_source.text[:500]}...\")\n        elif isinstance(data_source, Data):\n            print(f\"Data object: {data_source.data}\")\n        \n        # Handle different types of input\n        try:\n            if isinstance(data_source, Data):\n                # Handle Data object (from StructuredOutput component)\n                data_dict = data_source.data\n                \n                # Try to directly extract JSON from the text fields if present\n                if \"results\" in data_dict and isinstance(data_dict[\"results\"], list):\n                    # First, check if any individual field contains JSON_DATA\n                    for item in data_dict[\"results\"]:\n                        field_value = item.get(\"field\", \"\")\n                        if isinstance(field_value, str) and \"JSON_DATA:\" in field_value:\n                            print(f\"Found JSON_DATA in field: {field_value[:100]}...\")\n                            json_extract = self._extract_json_from_message(field_value)\n                            if json_extract:\n                                print(f\"Successfully extracted JSON from field\")\n                                return self._create_visualization_message(json_extract)\n                    \n                    # If no field had JSON_DATA, combine all fields and try again\n                    all_text = \" \".join([item.get(\"field\", \"\") for item in data_dict[\"results\"] if isinstance(item, dict) and \"field\" in item])\n                    if \"JSON_DATA:\" in all_text:\n                        json_extract = self._extract_json_from_message(all_text)\n                        if json_extract:\n                            print(f\"Successfully extracted JSON from combined field text\")\n                            return self._create_visualization_message(json_extract)\n                    \n                    # If still nothing, try to look for special format patterns like \"user:hours\" pairs\n                    # Extract user hours data\n                    users_with_hours = {}\n                    for item in data_dict[\"results\"]:\n                        field_value = item.get(\"field\", \"\")\n                        if isinstance(field_value, str):\n                            # Check for \"[user] total hours: [value]\" pattern\n                            if \" total hours:\" in field_value.lower():\n                                parts = field_value.split(\"total hours:\", 1)\n                                if len(parts) == 2:\n                                    user = parts[0].strip()\n                                    try:\n                                        hours = float(parts[1].strip())\n                                        users_with_hours[user] = hours\n                                    except ValueError:\n                                        pass\n                            # Also check for \"[entity]: [value]\" pattern\n                            elif \":\" in field_value and not any(x in field_value.lower() for x in [\"plot_type:\", \"title:\", \"x:\", \"y:\", \"mode:\"]):\n                                parts = field_value.split(\":\", 1)\n                                if len(parts) == 2:\n                                    try:\n                                        entity = parts[0].strip()\n                                        value = float(parts[1].strip())\n                                        users_with_hours[entity] = value\n                                    except ValueError:\n                                        pass\n                    \n                    if users_with_hours:\n                        print(f\"Found user-value pairs: {users_with_hours}\")\n                        # Found user hours data, create a visualization\n                        sorted_users = sorted(users_with_hours.items(), key=lambda x: x[1], reverse=True)\n                        x_values = [user for user, _ in sorted_users]\n                        y_values = [hours for _, hours in sorted_users]\n                        \n                        # Find a good title based on fields\n                        title = \"Data Visualization\"\n                        metric_field = None\n                        for item in data_dict[\"results\"]:\n                            field_value = item.get(\"field\", \"\")\n                            if \"metric:\" in field_value.lower():\n                                parts = field_value.split(\":\", 1)\n                                if len(parts) > 1:\n                                    metric_field = parts[1].strip()\n                                    title = f\"{metric_field.title()} by User\"\n                                    break\n                        \n                        json_data = {\n                            \"plot_type\": \"bar\",\n                            \"data\": [{\n                                \"type\": \"bar\",\n                                \"x\": x_values,\n                                \"y\": y_values,\n                                \"name\": \"Values\",\n                                \"marker\": {\"color\": \"steelblue\"}\n                            }],\n                            \"layout\": {\n                                \"title\": title,\n                                \"showlegend\": False,\n                                \"xaxis\": {\"title\": \"Entity\"},\n                                \"yaxis\": {\"title\": metric_field.title() if metric_field else \"Value\"}\n                            }\n                        }\n                        print(f\"Created visualization from user-value pairs: {json_data}\")\n                        return self._create_visualization_message(json_data)\n                \n                # Check for error message from StructuredOutput\n                if (isinstance(data_dict, dict) and \"message\" in data_dict and \n                    \"Visualization data is only available for Plotly Visualization output type\" in data_dict.get(\"message\", \"\")):\n                    return Message(\n                        text=\"Error: The StructuredOutput component is not configured for visualization. Please change the 'output_type' to 'Plotly Visualization' in the StructuredOutput component.\",\n                        sender=\"Bot\",\n                    )\n                \n                json_data = self._process_structured_output_data(data_dict)\n            elif isinstance(data_source, Message):\n                # Handle Message object (from CSV agent)\n                input_text = data_source.text\n                \n                # Direct extraction from CSV agent response \n                json_data = self._extract_json_from_message(input_text)\n                \n                # If we couldn't extract JSON directly, check if this is a structured output message\n                if not json_data and \"ANSWER:\" in input_text and \"JSON_DATA:\" in input_text:\n                    # This looks like a CSV agent response with our format\n                    json_data_match = re.search(r'JSON_DATA:\\s*```json\\s*(.*?)\\s*```', input_text, re.DOTALL)\n                    if json_data_match:\n                        try:\n                            json_str = json_data_match.group(1)\n                            json_data = json.loads(json_str)\n                            print(f\"Extracted JSON from CSV agent response\")\n                        except json.JSONDecodeError as e:\n                            print(f\"Failed to parse JSON from CSV agent: {e}\")\n            elif isinstance(data_source, dict):\n                # Handle direct dictionary input\n                json_data = self._process_structured_output_data(data_source)\n            elif isinstance(data_source, list):\n                # Handle list input directly\n                if len(data_source) > 0 and isinstance(data_source[0], dict):\n                    # If it's a list of dicts, use the first item as our visualization data\n                    json_data = data_source[0]\n                    # Check if this item has all required fields\n                    if not (\"plot_type\" in json_data or \"data\" in json_data):\n                        # If not, wrap it in a standard structure\n                        json_data = {\n                            \"plot_type\": \"bar\",\n                            \"data\": [{\"type\": \"bar\", \"x\": [], \"y\": []}],\n                            \"layout\": {\"title\": \"Chart\"}\n                        }\n                        # Try to extract data from the list\n                        if all(isinstance(item, dict) for item in data_source):\n                            # Extract keys for x axis (first item's keys)\n                            keys = list(data_source[0].keys())\n                            if len(keys) >= 2:  # Need at least 2 keys for x and y\n                                x_key = keys[0]\n                                y_key = keys[1]\n                                json_data[\"data\"][0][\"x\"] = [item.get(x_key) for item in data_source]\n                                json_data[\"data\"][0][\"y\"] = [item.get(y_key) for item in data_source]\n                                json_data[\"layout\"][\"title\"] = f\"{y_key} by {x_key}\"\n                                json_data[\"layout\"][\"xaxis\"] = {\"title\": x_key}\n                                json_data[\"layout\"][\"yaxis\"] = {\"title\": y_key}\n            elif isinstance(data_source, str):\n                # Handle string input\n                json_data = self._extract_json_from_message(data_source)\n            \n            # Log the processed data for debugging\n            print(f\"Processed data type: {type(json_data)}\")\n            if json_data:\n                print(f\"Processed data sample: {str(json_data)[:500]}...\")\n                # Check if there's data to visualize\n                if \"data\" in json_data and isinstance(json_data[\"data\"], list) and len(json_data[\"data\"]) > 0:\n                    data_item = json_data[\"data\"][0]\n                    has_data = False\n                    if \"x\" in data_item and isinstance(data_item[\"x\"], list) and len(data_item[\"x\"]) > 0:\n                        print(f\"Found x values: {data_item['x']}\")\n                        has_data = True\n                    if \"y\" in data_item and isinstance(data_item[\"y\"], list) and len(data_item[\"y\"]) > 0:\n                        print(f\"Found y values: {data_item['y']}\")\n                        has_data = True\n                    if not has_data:\n                        print(\"Warning: No x or y values found in the data\")\n            \n            if not json_data:\n                # Special case for CSV agent output\n                if isinstance(data_source, Message) and \"ANSWER:\" in data_source.text and \"JSON_DATA:\" in data_source.text:\n                    # Try to parse the output manually by extracting the relevant parts\n                    answer_match = re.search(r'ANSWER:(.*?)JSON_DATA:', data_source.text, re.DOTALL)\n                    json_data_match = re.search(r'JSON_DATA:\\s*```json\\s*(.*?)\\s*```', data_source.text, re.DOTALL)\n                    \n                    if not json_data_match:\n                        # Try without the ```json``` markers\n                        json_data_match = re.search(r'JSON_DATA:\\s*({.*})', data_source.text, re.DOTALL)\n                    \n                    if json_data_match:\n                        try:\n                            json_str = json_data_match.group(1).strip()\n                            # Remove any trailing backticks that might be present\n                            if json_str.endswith('```'):\n                                json_str = json_str[:-3]\n                            json_data = json.loads(json_str)\n                            print(f\"Extracted JSON from CSV agent response (method 2)\")\n                        except Exception as e:\n                            print(f\"Error parsing JSON from CSV agent: {e}\")\n                            print(f\"JSON string sample: {json_str[:100]}...\")\n                \n                if not json_data:\n                    # Last resort: try to handle entity-based data\n                    if isinstance(data_source, Data) and \"results\" in data_source.data:\n                        results = data_source.data[\"results\"]\n                        # Extract user hours data\n                        users_with_hours = {}\n                        for item in results:\n                            field_value = item.get(\"field\", \"\")\n                            if isinstance(field_value, str) and \" total hours:\" in field_value.lower():\n                                parts = field_value.split(\"total hours:\", 1)\n                                if len(parts) == 2:\n                                    user = parts[0].strip()\n                                    try:\n                                        hours = float(parts[1].strip())\n                                        users_with_hours[user] = hours\n                                    except ValueError:\n                                        pass\n                        \n                        if users_with_hours:\n                            # Found user hours data, create a visualization\n                            sorted_users = sorted(users_with_hours.items(), key=lambda x: x[1], reverse=True)\n                            x_values = [user for user, _ in sorted_users]\n                            y_values = [hours for _, hours in sorted_users]\n                            \n                            json_data = {\n                                \"plot_type\": \"bar\",\n                                \"data\": [{\n                                    \"type\": \"bar\",\n                                    \"x\": x_values,\n                                    \"y\": y_values,\n                                    \"name\": \"Total Hours Worked\",\n                                    \"marker\": {\"color\": \"steelblue\"}\n                                }],\n                                \"layout\": {\n                                    \"title\": \"Total Hours Worked by User\",\n                                    \"showlegend\": False,\n                                    \"xaxis\": {\"title\": \"User\"},\n                                    \"yaxis\": {\"title\": \"Total Hours\"}\n                                }\n                            }\n                            print(f\"Created visualization from user hours data: {json_data}\")\n                \n                if not json_data:\n                    return Message(\n                        text=\"Error: Could not extract valid JSON data from the input. Please check the format of your data.\",\n                        sender=\"Bot\",\n                    )\n                \n            # If json_data is a list, handle it appropriately\n            if isinstance(json_data, list):\n                if len(json_data) > 0 and isinstance(json_data[0], dict):\n                    # Check if first item looks like a complete chart definition\n                    first_item = json_data[0]\n                    if \"plot_type\" in first_item and \"data\" in first_item and \"layout\" in first_item:\n                        json_data = first_item\n                    else:\n                        # Convert list of objects to a bar chart\n                        # Example: [{name: \"A\", value: 10}, {name: \"B\", value: 20}]\n                        keys = list(json_data[0].keys())\n                        if len(keys) >= 2:\n                            chart_data = {\n                                \"plot_type\": \"bar\",\n                                \"data\": [{\n                                    \"type\": \"bar\",\n                                    \"x\": [item.get(keys[0]) for item in json_data],\n                                    \"y\": [item.get(keys[1]) for item in json_data],\n                                }],\n                                \"layout\": {\n                                    \"title\": f\"{keys[1]} by {keys[0]}\",\n                                    \"xaxis\": {\"title\": keys[0]},\n                                    \"yaxis\": {\"title\": keys[1]}\n                                }\n                            }\n                            json_data = chart_data\n                else:\n                    return Message(\n                        text=\"Error: Received a list but could not process it as visualization data.\",\n                        sender=\"Bot\",\n                    )\n                \n            # Get required fields from the schema\n            plot_type = json_data.get(\"plot_type\", \"bar\")\n            data_items = json_data.get(\"data\", [])\n            layout = json_data.get(\"layout\", {})\n            \n            if not data_items:\n                return Message(\n                    text=\"Error: No data items found in the input JSON. Please check that your data includes a non-empty 'data' array.\",\n                    sender=\"Bot\",\n                )\n            \n            return self._create_visualization_message(json_data)\n            \n        except Exception as e:\n            import traceback\n            error_trace = traceback.format_exc()\n            return Message(\n                text=f\"Error parsing JSON data: {str(e)}\\n\\nTraceback:\\n{error_trace}\\n\\nInput data:\\n{str(data_source)[:500]}...\",\n                sender=\"Bot\",\n            )\n\n    def _create_visualization_message(self, json_data):\n        \"\"\"Create a visualization message from JSON data.\"\"\"\n        try:\n            # Get required fields from the schema\n            plot_type = json_data.get(\"plot_type\", \"bar\")\n            data_items = json_data.get(\"data\", [])\n            layout = json_data.get(\"layout\", {})\n            \n            print(f\"Creating visualization with plot_type: {plot_type}, data items: {len(data_items)}\")\n            \n            # Apply custom colors if provided\n            custom_colors = None\n            if hasattr(self, 'customize_colors') and self.customize_colors:\n                custom_colors = [color.strip() for color in self.customize_colors.split(',')]\n                print(f\"Using custom colors: {custom_colors}\")\n                \n            # Create the appropriate Plotly figure based on plot_type\n            fig = go.Figure()\n            \n            for i, item in enumerate(data_items):\n                trace_type = item.get(\"type\", plot_type)\n                print(f\"Processing trace {i+1} of type: {trace_type}\")\n                \n                # Get x and y values\n                x_values = item.get(\"x\", [])\n                y_values = item.get(\"y\", [])\n                \n                if len(x_values) > 0:\n                    print(f\"X values: {x_values[:5]}{'...' if len(x_values) > 5 else ''}\")\n                if len(y_values) > 0:\n                    print(f\"Y values: {y_values[:5]}{'...' if len(y_values) > 5 else ''}\")\n                \n                # Apply custom color if available and prepare marker properties\n                base_marker = item.get(\"marker\", {})\n                \n                # Use provided colors if available, otherwise use default\n                if isinstance(base_marker, dict) and \"color\" in base_marker:\n                    # If marker.color is a list, use it directly\n                    marker = base_marker\n                    print(f\"Using provided marker colors\")\n                else:\n                    # If custom colors are specified, use them\n                    if custom_colors and i < len(custom_colors):\n                        marker_color = custom_colors[i]\n                    else:\n                        marker_color = \"steelblue\"  # Default color\n                    \n                    # Prepare marker object based on plot type\n                    if trace_type == \"bar\":\n                        marker = {\"color\": marker_color}\n                    elif trace_type in [\"scatter\", \"line\"]:\n                        marker = {\n                            \"color\": marker_color,\n                            \"size\": base_marker.get(\"size\", 6)\n                        }\n                    else:\n                        marker = base_marker or {\"color\": marker_color}\n                \n                # Create the appropriate trace based on type\n                if trace_type == \"bar\":\n                    fig.add_trace(\n                        go.Bar(\n                            x=x_values,\n                            y=y_values,\n                            name=item.get(\"name\", f\"Series {i+1}\"),\n                            marker=marker,\n                            orientation=item.get(\"orientation\", \"v\"),\n                        )\n                    )\n                elif trace_type == \"line\":\n                    fig.add_trace(\n                        go.Scatter(\n                            x=x_values,\n                            y=y_values,\n                            name=item.get(\"name\", f\"Series {i+1}\"),\n                            mode=item.get(\"mode\", \"lines\"),\n                            marker=marker,\n                            line=item.get(\"line\", {}),\n                        )\n                    )\n                elif trace_type == \"scatter\":\n                    fig.add_trace(\n                        go.Scatter(\n                            x=x_values,\n                            y=y_values,\n                            name=item.get(\"name\", f\"Series {i+1}\"),\n                            mode=item.get(\"mode\", \"markers\"),\n                            marker=marker,\n                        )\n                    )\n                elif trace_type == \"pie\":\n                    fig.add_trace(\n                        go.Pie(\n                            labels=item.get(\"labels\", []),\n                            values=item.get(\"values\", []),\n                            name=item.get(\"name\", f\"Series {i+1}\"),\n                            marker=marker,\n                        )\n                    )\n            \n            # Apply layout settings\n            title = layout.get(\"title\", \"Chart\")\n            fig.update_layout(\n                title=title,\n                showlegend=layout.get(\"showlegend\", True),\n                width=layout.get(\"width\"),\n                height=layout.get(\"height\", 500),\n                barmode=layout.get(\"barmode\"),\n                paper_bgcolor=layout.get(\"paper_bgcolor\"),\n                plot_bgcolor=layout.get(\"plot_bgcolor\"),\n            )\n            \n            # Apply axis settings if they exist\n            if \"xaxis\" in layout:\n                fig.update_xaxes(title_text=layout[\"xaxis\"].get(\"title\", \"\"))\n                \n            if \"yaxis\" in layout:\n                fig.update_yaxes(title_text=layout[\"yaxis\"].get(\"title\", \"\"))\n            \n            # Save plot to a temporary file\n            temp_dir = tempfile.gettempdir()\n            file_name = f\"plot_{hash(str(json_data))}.png\"\n            img_path = os.path.join(temp_dir, file_name)\n            \n            print(f\"Generating visualization image...\")\n            \n            # Write the image to the file\n            fig.write_image(img_path)\n            \n            # Create a base64 version as well\n            img_bytes = fig.to_image(format=\"png\")\n            base64_url = f\"data:image/png;base64,{base64.b64encode(img_bytes).decode('utf-8')}\"\n            \n            # Create the markdown with the embedded image\n            markdown_text = f\"## {title}\\n\\n![{title}]({base64_url})\"\n            \n            print(f\"Successfully created visualization for: {title}\")\n            \n            # Create the message\n            message = Message(\n                text=markdown_text,\n                sender=\"Bot\",\n            )\n            \n            return message\n        except Exception as e:\n            import traceback\n            error_trace = traceback.format_exc()\n            print(f\"Error creating visualization: {error_trace}\")\n            # Fallback to returning an error with the figure data if we can't generate an image\n            return Message(\n                text=f\"Error generating image: {str(e)}\\n\\nPlot data:\\n{json.dumps(json_data, indent=2)}\",\n                sender=\"Bot\",\n            )"
              },
              "customize_colors": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Customize Colors",
                "dynamic": false,
                "info": "Optional comma-separated colors to use (e.g., 'blue,red,green')",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "customize_colors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "structured_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Structured Data",
                "dynamic": false,
                "info": "The structured data from a StructuredOutput component or CSV agent response",
                "input_types": [
                  "Data",
                  "Message",
                  "dict",
                  "str"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "structured_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PlotlyVisualizerComponent"
        },
        "id": "PlotlyVisualizerComponent-02C8e",
        "measured": {
          "height": 293,
          "width": 320
        },
        "position": {
          "x": 3028.2768329426167,
          "y": 5392.702860727614
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "StructuredOutput-RfnPp",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Transforms LLM responses into **structured data formats**. Ideal for extracting specific information or creating consistent outputs.",
            "display_name": "Structured Output",
            "documentation": "",
            "edited": true,
            "field_order": [
              "llm",
              "input_value",
              "output_type",
              "custom_schema_system_prompt",
              "schema_name",
              "output_schema",
              "dashboard_schema_instructions",
              "multiple"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Structured Output",
                "hidden": null,
                "method": "build_structured_output",
                "name": "structured_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "hidden": null,
                "method": "as_dataframe",
                "name": "structured_output_dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Visualization Data",
                "hidden": false,
                "method": "get_visualization_data",
                "name": "visualization_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pydantic import BaseModel, Field, create_model\nfrom trustcall import create_extractor\nimport json\nfrom typing import List, Union, Dict, Any, Optional\n\nfrom langflow.base.models.chat_result import get_chat_result\nfrom langflow.custom import Component\nfrom langflow.helpers.base_model import build_model_from_schema\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TableInput,\n    DropdownInput,\n)\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.table import EditMode\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = (\n        \"Transforms LLM responses into **structured data formats**. Ideal for extracting specific information \"\n        \"or creating consistent outputs.\"\n    )\n    name = \"StructuredOutput\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Message\",\n            info=\"The input message to the language model.\",\n            tool_mode=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            info=\"Select the type of structured output to generate\",\n            options=[\"Custom Schema\", \"Dashboard Visualization\"],\n            value=\"Custom Schema\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"custom_schema_system_prompt\",\n            display_name=\"Custom Schema Instructions\",\n            info=\"The instructions to the language model for formatting the custom schema output.\",\n            value=(\n                \"You are an AI system designed to extract structured information from unstructured text.\"\n                \"Given the input_text, return a JSON object with predefined keys based on the expected structure.\"\n                \"Extract values accurately and format them according to the specified type \"\n                \"(e.g., string, integer, float, date).\"\n                \"If a value is missing or cannot be determined, return a default \"\n                \"(e.g., null, 0, or 'N/A').\"\n                \"If multiple instances of the expected structure exist within the input_text, \"\n                \"stream each as a separate JSON object.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Custom Output Schema\",\n            info=\"Define the structure and data types for the model's output when using Custom Schema.\",\n            required=False,\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\n                        \"Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).\"\n                    ),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"list\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"Multiple\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[\n                {\n                    \"name\": \"field\",\n                    \"description\": \"description of field\",\n                    \"type\": \"str\",\n                    \"multiple\": \"False\",\n                }\n            ],\n        ),\n        MultilineInput(\n            name=\"dashboard_schema_instructions\",\n            display_name=\"Dashboard Schema Instructions\",\n            info=\"Instructions for the language model on how to format the dashboard visualization data.\",\n            value=(\n                \"You are an AI system designed to analyze data and generate dashboard visualizations.\\n\\n\"\n                \"Given the user's input, create a JSON object following this structure:\\n\\n\"\n                \"{\\n\"\n                '  \"response\": {\\n'\n                '    \"answer\": \"Your direct answer to the user\\'s question\",\\n'\n                '    \"summary\": \"A brief summary of key insights\",\\n'\n                '    \"additional_insights\": [\"Insight 1\", \"Insight 2\"],\\n'\n                '    \"recommendations\": [\"Recommendation 1\", \"Recommendation 2\"]\\n'\n                \"  },\\n\"\n                '  \"visualization\": {\\n'\n                '    \"has_plots\": true,\\n'\n                '    \"display_mode\": \"dashboard\",\\n'\n                '    \"dashboard\": {\\n'\n                '      \"title\": \"Dashboard Title\",\\n'\n                '      \"subtitle\": \"Optional subtitle with metrics\",\\n'\n                '      \"auto_layout\": true,\\n'\n                '      \"plots\": [\\n'\n                \"        {\\n\"\n                '          \"id\": \"plot1\",\\n'\n                '          \"title\": \"Plot Title\",\\n'\n                '          \"description\": \"Plot description\",\\n'\n                '          \"importance\": 1,\\n'\n                '          \"plot_type\": \"bar|line|area|pie|scatter\",\\n'\n                '          \"data\": [\\n'\n                \"            {\\n\"\n                '              \"x\": [\"Category A\", \"Category B\"],\\n'\n                '              \"y\": [value1, value2],\\n'\n                '              \"type\": \"bar|line|area|pie|scatter\"\\n'\n                \"            }\\n\"\n                \"          ],\\n\"\n                '          \"layout\": {\\n'\n                '            \"height\": 300,\\n'\n                '            \"xaxis\": {\"title\": \"X-Axis Title\"},\\n'\n                '            \"yaxis\": {\"title\": \"Y-Axis Title\"}\\n'\n                \"          }\\n\"\n                \"        }\\n\"\n                \"      ]\\n\"\n                \"    }\\n\"\n                \"  },\\n\"\n                '  \"metadata\": {\\n'\n                '    \"total_records\": number,\\n'\n                '    \"time_period\": \"Period covered by data\",\\n'\n                '    \"data_sources\": [\"source1\", \"source2\"],\\n'\n                '    \"query_info\": {\\n'\n                '      \"original_query\": \"User\\'s original question\",\\n'\n                '      \"generated_plots\": number\\n'\n                \"    }\\n\"\n                \"  }\\n\"\n                \"}\\n\\n\"\n                \"Important guidelines:\\n\"\n                \"- Add 1-4 visualizations based on what best answers the user's question\\n\"\n                \"- Each plot should have a unique ID and descriptive title\\n\"\n                \"- For each plot, choose the most appropriate visualization type\\n\"\n                \"- Assign importance values (1=highest) to indicate display priority\\n\"\n                \"- Include meaningful insights and recommendations in the response section\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"multiple\",\n            advanced=True,\n            display_name=\"Generate Multiple\",\n            info=\"[Deprecated] Always set to True\",\n            value=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"structured_output\",\n            display_name=\"Structured Output\",\n            method=\"build_structured_output\",\n        ),\n        Output(\n            name=\"structured_output_dataframe\",\n            display_name=\"DataFrame\",\n            method=\"as_dataframe\",\n        ),\n        Output(\n            name=\"visualization_data\",\n            display_name=\"Visualization Data\",\n            method=\"get_visualization_data\",\n        ),\n    ]\n\n    def build_structured_output_base(self) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        \"\"\"Build structured output based on the selected output type.\"\"\"\n        if self.output_type == \"Custom Schema\":\n            print(f\"------------------>Custom Schema:{self._build_dashboard_schema_output}\")\n            return self._build_dashboard_schema_output()\n        elif self.output_type == \"Dashboard Visualization\":\n            print(f\"------------------>Dashboard Visualization:{self._build_dashboard_schema_output()}\")\n            return self._build_dashboard_schema_output()\n        else:\n            msg = f\"Unsupported output type: {self.output_type}\"\n            raise ValueError(msg)\n\n    def _build_custom_schema_output(self) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        \"\"\"Build output for the Custom Schema option.\"\"\"\n        schema_name = self.schema_name or \"OutputModel\"\n\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty for Custom Schema output type\"\n            raise ValueError(msg)\n\n        output_model_ = build_model_from_schema(self.output_schema)\n\n        output_model = create_model(\n            schema_name,\n            __doc__=f\"A list of {schema_name}.\",\n            objects=(list[output_model_], Field(description=f\"A list of {schema_name}.\")),  # type: ignore[valid-type]\n        )\n\n        try:\n            llm_with_structured_output = create_extractor(self.llm, tools=[output_model])\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        \n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        \n        # Use custom_schema_system_prompt if it exists, otherwise use a default prompt\n        system_prompt = self.custom_schema_system_prompt\n        if not system_prompt:\n            system_prompt = (\n                \"You are an AI system designed to extract structured information from unstructured text.\"\n                \"Given the input_text, return a JSON object with predefined keys based on the expected structure.\"\n                \"Extract values accurately and format them according to the specified type.\"\n            )\n            \n        result = get_chat_result(\n            runnable=llm_with_structured_output,\n            system_message=system_prompt,\n            input_value=self.input_value,\n            config=config_dict,\n        )\n        \n        if isinstance(result, BaseModel):\n            result = result.model_dump()\n        if responses := result.get(\"responses\"):\n            result = responses[0].model_dump()\n        if result and \"objects\" in result:\n            return result[\"objects\"]\n\n        return result\n\n    def _build_dashboard_schema_output(self) -> Dict[str, Any]:\n        \"\"\"Build output for the Dashboard Visualization option.\"\"\"\n        \n        # Define Pydantic models for dashboard schema validation\n        class ResponseModel(BaseModel):\n            answer: str\n            summary: str\n            additional_insights: List[str]\n            recommendations: List[str]\n\n        class PlotDataItem(BaseModel):\n            x: Optional[List[Union[str, int, float]]] = None\n            y: Optional[List[Union[str, int, float]]] = None\n            orientation: Optional[str] = None\n            type: Optional[str] = None\n            mode: Optional[str] = None\n            marker: Optional[Dict[str, Any]] = None\n            fill: Optional[str] = None\n            line: Optional[Dict[str, Any]] = None\n            fillcolor: Optional[str] = None\n            labels: Optional[List[str]] = None\n            values: Optional[List[Union[int, float]]] = None\n\n        class PlotLayout(BaseModel):\n            height: Optional[int] = None\n            width: Optional[int] = None\n            margin: Optional[Dict[str, int]] = None\n            xaxis: Optional[Dict[str, Any]] = None\n            yaxis: Optional[Dict[str, Any]] = None\n            title: Optional[str] = None\n            plot_bgcolor: Optional[str] = None\n            paper_bgcolor: Optional[str] = None\n\n        class PlotResponsive(BaseModel):\n            small: Optional[Dict[str, Any]] = None\n            large: Optional[Dict[str, Any]] = None\n\n        class Plot(BaseModel):\n            id: str\n            title: str\n            description: Optional[str] = None\n            importance: int\n            plot_type: str\n            data: List[PlotDataItem]\n            layout: PlotLayout\n            responsive: Optional[PlotResponsive] = None\n\n        class LayoutOptions(BaseModel):\n            default: Dict[str, Any]\n            single_plot: Optional[Dict[str, Any]] = None\n            two_plots: Optional[Dict[str, Any]] = None\n            three_plots: Optional[Dict[str, Any]] = None\n            four_plots: Optional[Dict[str, Any]] = None\n            many_plots: Optional[Dict[str, Any]] = None\n\n        class Dashboard(BaseModel):\n            title: str\n            subtitle: Optional[str] = None\n            auto_layout: Optional[bool] = True\n            plots: List[Plot]\n            layout_options: Optional[LayoutOptions] = None\n\n        class Visualization(BaseModel):\n            has_plots: bool\n            display_mode: str\n            dashboard: Dashboard\n\n        class QueryInfo(BaseModel):\n            original_query: str\n            generated_plots: int\n            processing_time_ms: Optional[int] = None\n\n        class Metadata(BaseModel):\n            total_records: Optional[int] = None\n            time_period: Optional[str] = None\n            data_sources: Optional[List[str]] = None\n            last_updated: Optional[str] = None\n            query_info: QueryInfo\n\n        class DashboardVisualizationModel(BaseModel):\n            response: ResponseModel\n            visualization: Visualization\n            metadata: Metadata\n\n        # Create the dashboard visualization model\n        dashboard_model = create_model(\n            \"DashboardVisualization\",\n            __doc__=\"Complete dashboard visualization with response, visualization data, and metadata.\",\n            dashboard=(DashboardVisualizationModel, Field(description=\"Dashboard visualization with user response and plots\"))\n        )\n\n        try:\n            system_prompt = self.dashboard_schema_instructions\n            \n            llm_with_structured_output = create_extractor(self.llm, tools=[dashboard_model])\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        \n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        \n        result = get_chat_result(\n            runnable=llm_with_structured_output,\n            system_message=system_prompt,\n            input_value=self.input_value,\n            config=config_dict,\n        )\n        \n        if isinstance(result, BaseModel):\n            result = result.model_dump()\n        if responses := result.get(\"responses\"):\n            result = responses[0].model_dump()\n        if result and \"dashboard\" in result:\n            return result[\"dashboard\"]\n            \n        return result\n\n    def build_structured_output(self) -> Data:\n        \"\"\"Return the structured output in a standard format.\"\"\"\n        output = self.build_structured_output_base()\n        return Data(text_key=\"results\", data={\"results\": output})\n\n    def as_dataframe(self) -> DataFrame:\n        \"\"\"Convert the structured output to a DataFrame.\"\"\"\n        output = self.build_structured_output_base()\n        if isinstance(output, list):\n            return DataFrame(data=output)\n        return DataFrame(data=[output])\n    \n    def get_visualization_data(self) -> Data:\n        \"\"\"Return the visualization data in a format that can be used by visualization components.\"\"\"\n        output = self.build_structured_output_base()\n        \n        # For Dashboard Visualization, return the visualization section directly\n        if self.output_type == \"Dashboard Visualization\" and isinstance(output, dict):\n            # If the output already has a 'visualization' key, return that\n            if \"visualization\" in output:\n                return Data(text_key=\"visualization\", data={\"visualization\": output[\"visualization\"]})\n            # Otherwise return the whole output as the visualization data\n            return Data(text_key=\"visualization\", data={\"visualization\": output})\n        \n        # For Custom Schema, simply return the output\n        return Data(text_key=\"visualization\", data={\"visualization\": output})"
              },
              "custom_schema_system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Custom Schema Instructions",
                "dynamic": false,
                "info": "The instructions to the language model for formatting the custom schema output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "custom_schema_system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI system designed to extract structured information from unstructured text.Given the input_text, return a JSON object with predefined keys based on the expected structure.Extract values accurately and format them according to the specified type (e.g., string, integer, float, date).If a value is missing or cannot be determined, return a default (e.g., null, 0, or 'N/A').If multiple instances of the expected structure exist within the input_text, stream each as a separate JSON object."
              },
              "dashboard_schema_instructions": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Dashboard Schema Instructions",
                "dynamic": false,
                "info": "Instructions for the language model on how to format the dashboard visualization data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "dashboard_schema_instructions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI system designed to analyze data and generate dashboard visualizations.\n\nGiven the user's input, create a JSON object following this structure:\n\n{\n  \"response\": {\n    \"answer\": \"Your direct answer to the user's question\",\n    \"summary\": \"A brief summary of key insights\",\n    \"additional_insights\": [\"Insight 1\", \"Insight 2\"],\n    \"recommendations\": [\"Recommendation 1\", \"Recommendation 2\"]\n  },\n  \"visualization\": {\n    \"has_plots\": true,\n    \"display_mode\": \"dashboard\",\n    \"dashboard\": {\n      \"title\": \"Dashboard Title\",\n      \"subtitle\": \"Optional subtitle with metrics\",\n      \"auto_layout\": true,\n      \"plots\": [\n        {\n          \"id\": \"plot1\",\n          \"title\": \"Plot Title\",\n          \"description\": \"Plot description\",\n          \"importance\": 1,\n          \"plot_type\": \"bar|line|area|pie|scatter\",\n          \"data\": [\n            {\n              \"x\": [\"Category A\", \"Category B\"],\n              \"y\": [value1, value2],\n              \"type\": \"bar|line|area|pie|scatter\"\n            }\n          ],\n          \"layout\": {\n            \"height\": 300,\n            \"xaxis\": {\"title\": \"X-Axis Title\"},\n            \"yaxis\": {\"title\": \"Y-Axis Title\"}\n          }\n        }\n      ]\n    }\n  },\n  \"metadata\": {\n    \"total_records\": number,\n    \"time_period\": \"Period covered by data\",\n    \"data_sources\": [\"source1\", \"source2\"],\n    \"query_info\": {\n      \"original_query\": \"User's original question\",\n      \"generated_plots\": number\n    }\n  }\n}\n\nImportant guidelines:\n- Add 1-4 visualizations based on what best answers the user's question\n- Each plot should have a unique ID and descriptive title\n- For each plot, choose the most appropriate visualization type\n- Assign importance values (1=highest) to indicate display priority\n- Include meaningful insights and recommendations in the response section"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The input message to the language model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "The language model to use to generate the structured output.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "multiple": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Generate Multiple",
                "dynamic": false,
                "info": "[Deprecated] Always set to True",
                "list": false,
                "list_add_label": "Add More",
                "name": "multiple",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Custom Output Schema",
                "dynamic": false,
                "info": "Define the structure and data types for the model's output when using Custom Schema.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "field",
                      "description": "Specify the name of the output field.",
                      "disable_edit": false,
                      "display_name": "Name",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "name",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "description of field",
                      "description": "Describe the purpose of the output field.",
                      "disable_edit": false,
                      "display_name": "Description",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "description",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "str",
                      "description": "Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).",
                      "disable_edit": false,
                      "display_name": "Type",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "type",
                      "options": [
                        "str",
                        "int",
                        "float",
                        "bool",
                        "list",
                        "dict"
                      ],
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": false,
                      "description": "Set to True if this output field should be a list of the specified type.",
                      "disable_edit": false,
                      "display_name": "Multiple",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "boolean",
                      "hidden": false,
                      "name": "multiple",
                      "sortable": true,
                      "type": "boolean"
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "description": "description of field",
                    "multiple": "False",
                    "name": "field",
                    "type": "str"
                  }
                ]
              },
              "output_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the type of structured output to generate",
                "name": "output_type",
                "options": [
                  "Custom Schema",
                  "Dashboard Visualization"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Custom Schema"
              },
              "schema_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Schema Name",
                "dynamic": false,
                "info": "Provide a name for the output data schema.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "schema_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "StructuredOutput"
        },
        "id": "StructuredOutput-RfnPp",
        "measured": {
          "height": 739,
          "width": 320
        },
        "position": {
          "x": 2476.966406462219,
          "y": 7521.249153628842
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CSVAgent-UoaOb",
          "node": {
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Construct a CSV agent from a CSV and tools that outputs structured dashboard visualizations.",
            "display_name": "CSVAgent",
            "documentation": "https://python.langchain.com/docs/modules/agents/toolkits/csv",
            "edited": true,
            "field_order": [
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "llm",
              "path",
              "agent_type",
              "input_value",
              "pandas_kwargs"
            ],
            "frozen": false,
            "icon": "LangChain",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": false,
                "method": "build_agent_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Agent",
                "hidden": true,
                "method": "build_agent",
                "name": "agent",
                "options": null,
                "required_inputs": null,
                "selected": "AgentExecutor",
                "tool_mode": false,
                "types": [
                  "AgentExecutor"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Agent Type",
                "dynamic": false,
                "info": "",
                "name": "agent_type",
                "options": [
                  "zero-shot-react-description",
                  "openai-functions",
                  "openai-tools"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "openai-tools"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent\n\nfrom langflow.base.agents.agent import LCAgentComponent\nfrom langflow.field_typing import AgentExecutor\nfrom langflow.inputs import DropdownInput, FileInput, HandleInput\nfrom langflow.inputs.inputs import DictInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass CSVAgentComponent(LCAgentComponent):\n    display_name = \"CSVAgent\"\n    description = \"Construct a CSV agent from a CSV and tools that outputs structured dashboard visualizations.\"\n    documentation = \"https://python.langchain.com/docs/modules/agents/toolkits/csv\"\n    name = \"CSVAgent\"\n    icon = \"LangChain\"\n\n    inputs = [\n        *LCAgentComponent._base_inputs,\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"An LLM Model Object (It can be found in any LLM Component).\",\n        ),\n        FileInput(\n            name=\"path\",\n            display_name=\"File Path\",\n            file_types=[\"csv\"],\n            input_types=[\"str\", \"Message\"],\n            required=True,\n            info=\"A CSV File or File Path.\",\n        ),\n        DropdownInput(\n            name=\"agent_type\",\n            display_name=\"Agent Type\",\n            advanced=True,\n            options=[\"zero-shot-react-description\", \"openai-functions\", \"openai-tools\"],\n            value=\"openai-tools\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input and extract info from the CSV File.\",\n            required=True,\n        ),\n        DictInput(\n            name=\"pandas_kwargs\",\n            display_name=\"Pandas Kwargs\",\n            info=\"Pandas Kwargs to be passed to the agent.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response\", method=\"build_agent_response\"),\n        Output(display_name=\"Agent\", name=\"agent\", method=\"build_agent\", hidden=True, tool_mode=False),\n    ]\n\n    def _path(self) -> str:\n        if isinstance(self.path, Message) and isinstance(self.path.text, str):\n            return self.path.text\n        return self.path\n\n    def _create_structured_prompt(self, user_query: str) -> str:\n        # Create the prompt parts separately\n        prompt_intro = f\"User query: {user_query}\\n\\n\"\n        \n        # Define the enhanced dashboard schema prompt instructions\n        prompt_instructions = \"\"\"\nSystem Instructions:  \nYou are a data analysis AI specialized in creating interactive dashboards. Analyze the data in the CSV file, answer the user's query, and provide a comprehensive dashboard response.\n\nYour response **MUST** follow this specific structure:\n\n```json\n{\n  \"response\": {\n    \"answer\": \"Your direct answer to the user's question goes here.\",\n    \"summary\": \"A brief summary of the key insights from the data analysis.\",\n    \"additional_insights\": [\n      \"Additional insight point 1 that might be helpful\",\n      \"Additional insight point 2 that provides more context\"\n    ],\n    \"recommendations\": [\n      \"Recommendation 1 based on the data\",\n      \"Recommendation 2 for potential actions\"\n    ]\n  },\n  \"visualization\": {\n    \"has_plots\": true,\n    \"display_mode\": \"dashboard\",\n    \"dashboard\": {\n      \"title\": \"Dashboard Title Based on the User's Query\",\n      \"subtitle\": \"Optional subtitle with key metrics (e.g., Total Hours: 223.25)\",\n      \"auto_layout\": true,\n      \"plots\": [\n        {\n          \"id\": \"plot1\",\n          \"title\": \"Primary Visualization Title\",\n          \"description\": \"Describes what this visualization shows\",\n          \"importance\": 1,\n          \"plot_type\": \"bar|line|area|pie|scatter\",\n          \"data\": [\n            {\n              \"x\": [\"Category A\", \"Category B\", \"Category C\"],\n              \"y\": [20, 35, 15],\n              \"type\": \"bar|line|area|pie|scatter\",\n              \"orientation\": \"v|h\",\n              \"mode\": \"lines+markers\",\n              \"marker\": {\n                \"color\": \"blue\"\n              }\n            }\n          ],\n          \"layout\": {\n            \"height\": 300,\n            \"margin\": {\"t\": 30, \"b\": 40, \"l\": 60, \"r\": 20},\n            \"xaxis\": {\n              \"title\": \"X-Axis Title\"\n            },\n            \"yaxis\": {\n              \"title\": \"Y-Axis Title\"\n            }\n          }\n        }\n      ]\n    }\n  },\n  \"metadata\": {\n    \"total_records\": 223,\n    \"time_period\": \"The time range covered by the data\",\n    \"data_sources\": [\"report.csv\"],\n    \"last_updated\": \"2025-05-20T10:30:00Z\",\n    \"query_info\": {\n      \"original_query\": \"The user's original question\",\n      \"generated_plots\": 1\n    }\n  }\n}\n```\n\nImportant Guidelines:\n\n1. **RESPONSE SECTION**:\n   - Provide a direct, concise answer to the user's question\n   - Include a summary of key insights\n   - List 2-3 additional insights not directly asked but relevant\n   - Suggest 1-2 actionable recommendations based on the data\n\n2. **VISUALIZATION DECISION**:\n   - Carefully analyze the user's question to determine the appropriate number of plots:\n     - **Simple Questions**: For straightforward queries like \"How many hours did JSmith work?\" or \"What's the average time per task?\", use a SINGLE plot that directly answers the question\n     - **Comparative Questions**: For queries like \"Compare hours worked by each employee\" or \"Show me time distribution by project\", use 1-2 plots to highlight the comparison\n     - **Complex Questions**: For multi-faceted questions like \"Analyze our time tracking data\" or \"Give me a full breakdown of our project efficiency\", create 3-4 plots that show different aspects of the data\n   - **NEVER exceed 4 plots** in your response\n   - Use the \"importance\" field to rank plots (1 = most important)\n   - Update the \"generated_plots\" count in metadata to match the actual number of plots\n\n3. **VISUALIZATION TYPES**:\n   - Choose appropriate plot types for the data:\n     - **Bar charts**: For comparisons across discrete categories (e.g., employees, projects)\n     - **Line/area charts**: For time series or trends over time\n     - **Pie charts**: For proportions or composition when there are fewer than 7 categories\n     - **Scatter plots**: For relationship analysis between two variables\n   - Ensure each plot has a clear title and axis labels\n   - Set \"has_plots\" to false and \"display_mode\" to \"none\" if visualization isn't appropriate\n\n4. **PLOT SPECIFICS**:\n   - For time data, format dates consistently (e.g., \"2023-01\" for months)\n   - For horizontal bar charts, set \"orientation\": \"h\" and swap x/y values\n   - Use colors strategically (gradients for categories, consistent palette)\n   - Ensure all required fields for each plot type are included\n   - For multiple plots, make sure each has a unique \"id\" (plot1, plot2, etc.)\n\n5. **METADATA**:\n   - Include accurate record counts and date ranges from the data\n   - List data sources used (file names)\n   - Include the original user query\n   - Specify how many plots were generated\n\nEnsure your JSON is properly structured, with no syntax errors, and contains all required fields. The analysis should be data-driven and directly answer the user's question.\n\"\"\"\n        \n        # Combine the parts\n        return prompt_intro + prompt_instructions\n\n    def build_agent_response(self) -> Message:\n        agent_kwargs = {\n            \"verbose\": self.verbose,\n            \"allow_dangerous_code\": True,\n        }\n\n        agent_csv = create_csv_agent(\n            llm=self.llm,\n            path=self._path(),\n            agent_type=self.agent_type,\n            handle_parsing_errors=self.handle_parsing_errors,\n            pandas_kwargs=self.pandas_kwargs,\n            **agent_kwargs,\n        )\n        \n        # Structure the prompt with the user's query\n        structured_prompt = self._create_structured_prompt(self.input_value)\n        \n        # Pass the structured prompt to the agent\n        result = agent_csv.invoke({\"input\": structured_prompt})\n        \n        # Process the result to extract the JSON if needed\n        response_text = str(result[\"output\"])\n        \n        # Attempt to find and clean JSON from the response if needed\n        # This handles cases where the LLM might add extra text before or after the JSON\n        import re\n        import json\n        \n        # Try to extract JSON if it's embedded in text\n        json_pattern = r'```json\\s*([\\s\\S]*?)\\s*```|^\\s*(\\{[\\s\\S]*\\})\\s*$'\n        match = re.search(json_pattern, response_text)\n        \n        if match:\n            # Get the matched JSON string (either from code block or raw)\n            json_str = match.group(1) or match.group(2)\n            \n            try:\n                # Parse the JSON to validate it\n                parsed_json = json.loads(json_str.strip())\n                # Return just the validated JSON as the response\n                return Message(text=json.dumps(parsed_json, indent=2))\n            except json.JSONDecodeError:\n                # If JSON is invalid, return the original response\n                pass\n        \n        return Message(text=response_text)\n\n    def build_agent(self) -> AgentExecutor:\n        agent_kwargs = {\n            \"verbose\": self.verbose,\n            \"allow_dangerous_code\": True,\n        }\n\n        agent_csv = create_csv_agent(\n            llm=self.llm,\n            path=self._path(),\n            agent_type=self.agent_type,\n            handle_parsing_errors=self.handle_parsing_errors,\n            pandas_kwargs=self.pandas_kwargs,\n            **agent_kwargs,\n        )\n\n        self.status = Message(text=str(agent_csv))\n\n        return agent_csv"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input and extract info from the CSV File.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "An LLM Model Object (It can be found in any LLM Component).",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "pandas_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Pandas Kwargs",
                "dynamic": false,
                "info": "Pandas Kwargs to be passed to the agent.",
                "list": true,
                "list_add_label": "Add More",
                "name": "pandas_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "File Path",
                "dynamic": false,
                "fileTypes": [
                  "csv"
                ],
                "file_path": "1752bbdd-9926-4869-b737-f02b125c1650/8a8d73b3-8d2c-4846-babc-38af98304f02.csv",
                "info": "A CSV File or File Path.",
                "input_types": [
                  "str",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "path",
                "placeholder": "",
                "required": true,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CSVAgent"
        },
        "id": "CSVAgent-UoaOb",
        "measured": {
          "height": 401,
          "width": 320
        },
        "position": {
          "x": 1916.636416588734,
          "y": 6939.386610450343
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-EdzLE",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider. ",
            "display_name": "Language Model",
            "documentation": "",
            "edited": false,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "key": "LanguageModelComponent",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "score": 0.002952328684912448,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_openai import ChatOpenAI\n\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, SecretStrInput, SliderInput\nfrom langflow.schema.dotdict import dotdict\n\n\nclass LanguageModelComponent(LCModelComponent):\n    display_name = \"Language Model\"\n    description = \"Runs a language model given a specified provider. \"\n    icon = \"brain-circuit\"\n    category = \"models\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Model Provider\",\n            options=[\"OpenAI\", \"Anthropic\"],\n            value=\"OpenAI\",\n            info=\"Select the model provider\",\n            real_time_refresh=True,\n            options_metadata=[{\"icon\": \"OpenAI\"}, {\"icon\": \"Anthropic\"}],\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n            info=\"Select the model to use\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"Model Provider API key\",\n            required=False,\n            show=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input text to send to the model\",\n        ),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"A system message that helps set the behavior of the assistant\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=\"Whether to stream the response\",\n            value=False,\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Controls randomness in responses\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        provider = self.provider\n        model_name = self.model_name\n        temperature = self.temperature\n        stream = self.stream\n\n        if provider == \"OpenAI\":\n            if not self.api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n            return ChatOpenAI(\n                model_name=model_name,\n                temperature=temperature,\n                streaming=stream,\n                openai_api_key=self.api_key,\n            )\n        if provider == \"Anthropic\":\n            if not self.api_key:\n                msg = \"Anthropic API key is required when using Anthropic provider\"\n                raise ValueError(msg)\n            return ChatAnthropic(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                anthropic_api_key=self.api_key,\n            )\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"provider\":\n            if field_value == \"OpenAI\":\n                build_config[\"model_name\"][\"options\"] = OPENAI_MODEL_NAMES\n                build_config[\"model_name\"][\"value\"] = OPENAI_MODEL_NAMES[0]\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\n            elif field_value == \"Anthropic\":\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4.1"
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "Select the model provider",
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "OpenAI"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "id": "LanguageModelComponent-EdzLE",
        "measured": {
          "height": 543,
          "width": 320
        },
        "position": {
          "x": 1101.6844561351027,
          "y": 6882.636932702033
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PlotlyVisualizerComponent-6JNkF",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates dashboard visualizations from structured JSON data with user response",
            "display_name": "Plotly Visualizer",
            "documentation": "",
            "edited": true,
            "field_order": [
              "structured_data",
              "customize_colors"
            ],
            "frozen": false,
            "icon": "chart-bar",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "hidden": false,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output, HandleInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport io\nimport base64\nimport tempfile\nimport os\nimport json\nimport re\nimport ast\nfrom typing import Dict, List, Any, Optional, Union\n\nclass PlotlyVisualizerComponent(Component):\n    display_name = \"Plotly Visualizer\"\n    description = \"Creates dashboard visualizations from structured JSON data with user response\"\n    icon = \"chart-bar\"\n    name = \"PlotlyVisualizerComponent\"\n\n    inputs = [\n        HandleInput(\n            name=\"structured_data\",\n            display_name=\"Structured Data\",\n            info=\"The structured data from a StructuredOutput component or CSV agent response\",\n            input_types=[\"Data\", \"Message\", \"dict\", \"str\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"customize_colors\",\n            display_name=\"Customize Colors\",\n            info=\"Optional comma-separated colors to use (e.g., 'blue,red,green')\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def _extract_json_from_message(self, text):\n        \"\"\"Extract JSON data from text.\"\"\"\n        if not text:\n            return None\n            \n        print(f\"Extracting JSON from text: {text[:100]}...\") # Show first 100 chars only\n        \n        # Try to directly parse the text as JSON\n        try:\n            return json.loads(text)\n        except json.JSONDecodeError:\n            pass\n        \n        # Look for JSON in code blocks\n        json_code_pattern = r'```(?:json)?\\s*([\\s\\S]*?)\\s*```'\n        matches = re.findall(json_code_pattern, text, re.DOTALL)\n        \n        for json_str in matches:\n            try:\n                return json.loads(json_str.strip())\n            except json.JSONDecodeError:\n                continue\n                \n        # Look for any JSON object in the text\n        json_pattern = r'(\\{[\\s\\S]*?\\})'\n        match = re.search(json_pattern, text, re.DOTALL)\n        \n        if match:\n            json_str = match.group(1)\n            try:\n                return json.loads(json_str)\n            except json.JSONDecodeError:\n                pass\n                \n        return None\n\n    def _safely_get_attr_or_dict_val(self, obj, key, default=None):\n        \"\"\"Safely get a value from an object or dictionary.\"\"\"\n        # If obj is a dictionary\n        if isinstance(obj, dict):\n            return obj.get(key, default)\n        \n        # If obj is an object with attributes\n        try:\n            return getattr(obj, key, default)\n        except (AttributeError, TypeError):\n            pass\n        \n        # If obj has a __dict__ attribute (like some message objects)\n        try:\n            if hasattr(obj, '__dict__'):\n                obj_dict = obj.__dict__\n                if isinstance(obj_dict, dict) and key in obj_dict:\n                    return obj_dict[key]\n        except (AttributeError, TypeError):\n            pass\n            \n        # If obj has a 'dict' method (like some Pydantic models)\n        try:\n            if hasattr(obj, 'dict') and callable(getattr(obj, 'dict')):\n                obj_dict = obj.dict()\n                if isinstance(obj_dict, dict) and key in obj_dict:\n                    return obj_dict[key]\n        except (AttributeError, TypeError):\n            pass\n        \n        # Default case - try to access as dictionary (will raise appropriate error if impossible)\n        try:\n            return obj[key]\n        except (KeyError, TypeError):\n            return default\n\n    def _extract_dashboard_from_tool_calls(self, data):\n        \"\"\"Extract dashboard data from tool calls structure.\"\"\"\n        if not isinstance(data, dict) and not hasattr(data, '__dict__'):\n            return None\n            \n        # Extract from Messages structure\n        messages = self._safely_get_attr_or_dict_val(data, \"messages\", [])\n        if not messages:\n            return None\n            \n        for message in messages:\n            # Look for tool_calls in the message\n            tool_calls = self._safely_get_attr_or_dict_val(message, \"tool_calls\", [])\n            \n            # If no direct tool_calls, try additional_kwargs\n            if not tool_calls:\n                additional_kwargs = self._safely_get_attr_or_dict_val(message, \"additional_kwargs\", {})\n                tool_calls = self._safely_get_attr_or_dict_val(additional_kwargs, \"tool_calls\", [])\n            \n            # Process tool calls if found\n            for tool_call in tool_calls:\n                # Try to get 'args' - could be attribute or dictionary key\n                args = self._safely_get_attr_or_dict_val(tool_call, \"args\", {})\n                \n                # Check if dashboard is directly in args\n                if \"dashboard\" in args:\n                    return args[\"dashboard\"]\n                \n                # Check for direct response/visualization structure in args\n                if \"response\" in args and \"visualization\" in args:\n                    return args\n                    \n                # Check for nested structures in args values\n                for key, value in args.items() if isinstance(args, dict) else []:\n                    if isinstance(value, dict) and \"response\" in value and \"visualization\" in value:\n                        return value\n            \n            # Also try direct content as a fallback\n            content = self._safely_get_attr_or_dict_val(message, \"content\", \"\")\n            if isinstance(content, str) and content:\n                try:\n                    content_json = json.loads(content)\n                    if isinstance(content_json, dict):\n                        # Check for dashboard structure\n                        if \"response\" in content_json and \"visualization\" in content_json:\n                            return content_json\n                except json.JSONDecodeError:\n                    pass\n        \n        return None\n\n    def _process_dashboard_data(self, data):\n        \"\"\"Process data for the new dashboard schema.\"\"\"\n        if not data:\n            return None\n            \n        # Check if this is already in the dashboard schema format\n        if isinstance(data, dict) or hasattr(data, '__dict__'):\n            # First, try to extract from tool calls structure\n            tool_calls_result = self._extract_dashboard_from_tool_calls(data)\n            if tool_calls_result:\n                print(\"Successfully extracted dashboard data from tool calls\")\n                return tool_calls_result\n                \n            # If visualization and response are present, this is likely our format\n            if self._safely_get_attr_or_dict_val(data, \"visualization\") and self._safely_get_attr_or_dict_val(data, \"response\"):\n                return data\n                \n            # If data structure matches, but it's under results\n            results = self._safely_get_attr_or_dict_val(data, \"results\")\n            if results and isinstance(results, dict):\n                if self._safely_get_attr_or_dict_val(results, \"visualization\") and self._safely_get_attr_or_dict_val(results, \"response\"):\n                    return results\n                    \n            # If the data is in a different key\n            for key, value in data.items() if isinstance(data, dict) else []:\n                if isinstance(value, dict) or hasattr(value, '__dict__'):\n                    # Check if this is the dashboard format\n                    if self._safely_get_attr_or_dict_val(value, \"response\") and self._safely_get_attr_or_dict_val(value, \"visualization\"):\n                        return value\n                        \n                    # Try to extract from tool calls within this value\n                    tool_calls_result = self._extract_dashboard_from_tool_calls(value)\n                    if tool_calls_result:\n                        print(f\"Successfully extracted dashboard data from tool calls in {key}\")\n                        return tool_calls_result\n                    \n            # Dashboard may be found in the visualization key\n            visualization = self._safely_get_attr_or_dict_val(data, \"visualization\")\n            if visualization and isinstance(visualization, dict):\n                # Check if the full structure is under visualization\n                if self._safely_get_attr_or_dict_val(visualization, \"response\"):\n                    return visualization\n                \n                # Sometimes the visualization only contains the dashboard part\n                if self._safely_get_attr_or_dict_val(visualization, \"dashboard\"):\n                    # Check if response is at the top level\n                    if self._safely_get_attr_or_dict_val(data, \"response\"):\n                        return data  # Full structure at top level\n                        \n            # Or it might be that we have incomplete data structure\n            if self._safely_get_attr_or_dict_val(data, \"dashboard\") or self._safely_get_attr_or_dict_val(data, \"plots\"):\n                # Try to piece together a complete structure\n                dashboard_data = {\n                    \"response\": self._safely_get_attr_or_dict_val(data, \"response\", {\n                        \"answer\": \"Data analysis results\",\n                        \"summary\": \"Visualization generated from data\",\n                        \"additional_insights\": [],\n                        \"recommendations\": []\n                    }),\n                    \"visualization\": {\n                        \"has_plots\": True,\n                        \"display_mode\": \"dashboard\",\n                        \"dashboard\": self._safely_get_attr_or_dict_val(data, \"dashboard\", {})\n                    },\n                    \"metadata\": self._safely_get_attr_or_dict_val(data, \"metadata\", {})\n                }\n                \n                # If plots are at the top level, move them to dashboard\n                plots = self._safely_get_attr_or_dict_val(data, \"plots\")\n                if plots and self._safely_get_attr_or_dict_val(dashboard_data[\"visualization\"], \"dashboard\"):\n                    dashboard_data[\"visualization\"][\"dashboard\"][\"plots\"] = plots\n                    \n                return dashboard_data\n                \n        return None\n\n    def build_output(self) -> Message:\n        # Process the input data\n        print(f\"--------------->structured_data:{self.structured_data}\")\n        data_source = self.structured_data\n        dashboard_data = None\n        \n        # Log input type for debugging\n        print(f\"Input data type: {type(data_source)}\")\n        if isinstance(data_source, Message):\n            print(f\"Message text sample: {data_source.text[:100]}...\")\n        elif isinstance(data_source, Data):\n            data_dict = data_source.data\n            print(f\"Data object keys: {data_dict.keys() if isinstance(data_dict, dict) else 'Not a dict'}\")\n        \n        # Handle different types of input\n        try:\n            if isinstance(data_source, Data):\n                # Extract data from Data object\n                data_dict = data_source.data\n                \n                # Try to process as dashboard data\n                dashboard_data = self._process_dashboard_data(data_dict)\n                \n                # If not in dashboard format, try to extract JSON\n                text_key = self._safely_get_attr_or_dict_val(data_dict, \"text_key\")\n                if not dashboard_data and text_key and text_key in data_dict:\n                    text_content = data_dict[text_key]\n                    if isinstance(text_content, str):\n                        extracted_json = self._extract_json_from_message(text_content)\n                        dashboard_data = self._process_dashboard_data(extracted_json)\n                \n                # Try to extract from results if it exists\n                if not dashboard_data:\n                    results = self._safely_get_attr_or_dict_val(data_dict, \"results\")\n                    if results:\n                        dashboard_data = self._process_dashboard_data(results)\n                    \n            elif isinstance(data_source, Message):\n                # Try to extract JSON from message text\n                extracted_json = self._extract_json_from_message(data_source.text)\n                dashboard_data = self._process_dashboard_data(extracted_json)\n                \n            elif isinstance(data_source, dict):\n                # Try to process dict directly\n                dashboard_data = self._process_dashboard_data(data_source)\n                \n            elif isinstance(data_source, str):\n                # Try to extract JSON from string\n                extracted_json = self._extract_json_from_message(data_source)\n                dashboard_data = self._process_dashboard_data(extracted_json)\n            \n            # Debugging information\n            if dashboard_data:\n                if isinstance(dashboard_data, dict):\n                    print(f\"Dashboard data found with keys: {dashboard_data.keys()}\")\n                else:\n                    print(f\"Dashboard data found but is not a dict. Type: {type(dashboard_data)}\")\n            \n            # Check if we have valid dashboard data\n            if not dashboard_data:\n                fallback_data = None\n                \n                # If we have a dict but not in dashboard format, try to use legacy format\n                if isinstance(data_source, dict) or (isinstance(data_source, Data) and isinstance(data_source.data, dict)):\n                    data_to_check = data_source.data if isinstance(data_source, Data) else data_source\n                    \n                    # Check for legacy plotly format\n                    if isinstance(data_to_check, dict) and \"plot_type\" in data_to_check and \"data\" in data_to_check:\n                        fallback_data = data_to_check\n                \n                # If we found legacy data, adapt it to the new format\n                if fallback_data:\n                    print(\"Using legacy format and adapting to dashboard schema\")\n                    dashboard_data = {\n                        \"response\": {\n                            \"answer\": \"Data visualization generated from legacy format\",\n                            \"summary\": \"Visualization created from plotly data\",\n                            \"additional_insights\": [],\n                            \"recommendations\": []\n                        },\n                        \"visualization\": {\n                            \"has_plots\": True,\n                            \"display_mode\": \"single\",\n                            \"dashboard\": {\n                                \"title\": self._safely_get_attr_or_dict_val(fallback_data.get(\"layout\", {}), \"title\", \"Data Visualization\"),\n                                \"auto_layout\": True,\n                                \"plots\": [{\n                                    \"id\": \"plot1\",\n                                    \"title\": self._safely_get_attr_or_dict_val(fallback_data.get(\"layout\", {}), \"title\", \"Visualization\"),\n                                    \"importance\": 1,\n                                    \"plot_type\": fallback_data.get(\"plot_type\", \"bar\"),\n                                    \"data\": fallback_data.get(\"data\", []),\n                                    \"layout\": fallback_data.get(\"layout\", {})\n                                }]\n                            }\n                        },\n                        \"metadata\": {\n                            \"generated_plots\": 1\n                        }\n                    }\n                else:\n                    return Message(\n                        text=\"Error: Could not extract valid dashboard data from the input. Please check that your data follows the required schema.\",\n                        sender=\"Bot\",\n                    )\n            \n            return self._create_dashboard_message(dashboard_data)\n            \n        except Exception as e:\n            import traceback\n            error_trace = traceback.format_exc()\n            return Message(\n                text=f\"Error processing dashboard data: {str(e)}\\n\\nTraceback:\\n{error_trace}\",\n                sender=\"Bot\",\n            )\n\n    def _format_text_response(self, response_data):\n        \"\"\"Format the text response part of the dashboard.\"\"\"\n        if not response_data:\n            return \"No response data available.\"\n            \n        text_parts = []\n        \n        # Add the main answer\n        answer = self._safely_get_attr_or_dict_val(response_data, \"answer\")\n        if answer:\n            text_parts.append(f\"**{answer}**\\n\")\n        \n        # Add the summary\n        summary = self._safely_get_attr_or_dict_val(response_data, \"summary\")\n        if summary:\n            text_parts.append(f\"{summary}\\n\")\n        \n        # Add additional insights\n        insights = self._safely_get_attr_or_dict_val(response_data, \"additional_insights\", [])\n        if insights:\n            text_parts.append(\"\\n**Additional Insights:**\")\n            for insight in insights:\n                text_parts.append(f\"- {insight}\")\n            text_parts.append(\"\")\n        \n        # Add recommendations\n        recommendations = self._safely_get_attr_or_dict_val(response_data, \"recommendations\", [])\n        if recommendations:\n            text_parts.append(\"**Recommendations:**\")\n            for recommendation in recommendations:\n                text_parts.append(f\"- {recommendation}\")\n        \n        return \"\\n\".join(text_parts)\n    \n    def _determine_trace_types(self, plots):\n        \"\"\"Determine the trace types for each plot to create proper subplot specs.\"\"\"\n        trace_types = []\n        for plot in plots:\n            # Default to 'xy' for most plot types\n            plot_type = 'xy'\n            \n            # Check if this is a pie chart\n            data_items = self._safely_get_attr_or_dict_val(plot, \"data\", [])\n            for item in data_items:\n                item_type = self._safely_get_attr_or_dict_val(item, \"type\")\n                plot_plot_type = self._safely_get_attr_or_dict_val(plot, \"plot_type\")\n                \n                if item_type == \"pie\" or (not item_type and plot_plot_type == \"pie\"):\n                    plot_type = 'domain'\n                    break\n            \n            trace_types.append(plot_type)\n        \n        return trace_types\n\n    def _create_dashboard_message(self, dashboard_data):\n        \"\"\"Create a message with text response and dashboard visualization.\"\"\"\n        try:\n            # Extract components\n            response_data = self._safely_get_attr_or_dict_val(dashboard_data, \"response\", {})\n            visualization_data = self._safely_get_attr_or_dict_val(dashboard_data, \"visualization\", {})\n            metadata = self._safely_get_attr_or_dict_val(dashboard_data, \"metadata\", {})\n            \n            # Format the text response\n            text_response = self._format_text_response(response_data)\n            \n            # Check if visualization is enabled\n            has_plots = self._safely_get_attr_or_dict_val(visualization_data, \"has_plots\", True)\n            if not has_plots:\n                # If no plots, just return the text response\n                return Message(\n                    text=text_response,\n                    sender=\"Bot\",\n                )\n            \n            # Get dashboard data\n            dashboard = self._safely_get_attr_or_dict_val(visualization_data, \"dashboard\", {})\n            plots = self._safely_get_attr_or_dict_val(dashboard, \"plots\", [])\n            \n            if not plots:\n                # If no plots defined, just return the text response\n                return Message(\n                    text=text_response,\n                    sender=\"Bot\",\n                )\n            \n            # Sort plots by importance\n            plots = sorted(plots, key=lambda x: self._safely_get_attr_or_dict_val(x, \"importance\", 999))\n            \n            # Get dashboard title and subtitle\n            dashboard_title = self._safely_get_attr_or_dict_val(dashboard, \"title\", \"Data Dashboard\")\n            dashboard_subtitle = self._safely_get_attr_or_dict_val(dashboard, \"subtitle\", \"\")\n            \n            # Determine layout based on number of plots\n            num_plots = len(plots)\n            \n            # Apply custom colors if provided\n            custom_colors = None\n            if hasattr(self, 'customize_colors') and self.customize_colors:\n                custom_colors = [color.strip() for color in self.customize_colors.split(',')]\n                print(f\"Using custom colors: {custom_colors}\")\n            \n            # Create figure with appropriate subplot configuration\n            if num_plots == 1:\n                # Single plot\n                fig = go.Figure()\n                self._add_traces_to_figure(fig, plots[0], custom_colors)\n                \n                # Extract layout without the title to avoid conflicts\n                plot_layout = self._safely_get_attr_or_dict_val(plots[0], \"layout\", {}).copy() if self._safely_get_attr_or_dict_val(plots[0], \"layout\") else {}\n                if \"title\" in plot_layout:\n                    del plot_layout[\"title\"]  # Remove title from layout to avoid conflict\n                \n                # Apply the layout with the title separately\n                fig.update_layout(\n                    title=self._safely_get_attr_or_dict_val(plots[0], \"title\", \"Visualization\"),\n                    **plot_layout\n                )\n            else:\n                # Multiple plots - first determine trace types for compatible subplot configuration\n                trace_types = self._determine_trace_types(plots)\n                \n                if num_plots <= 2:\n                    # Two plots: vertical arrangement\n                    fig = make_subplots(\n                        rows=2, cols=1, \n                        subplot_titles=[self._safely_get_attr_or_dict_val(plot, \"title\", f\"Plot {i+1}\") for i, plot in enumerate(plots[:2])],\n                        vertical_spacing=0.15,\n                        specs=[[{\"type\": trace_types[0]}], [{\"type\": trace_types[1 if len(trace_types) > 1 else 0]}]]\n                    )\n                    for i, plot in enumerate(plots[:2]):\n                        self._add_traces_to_figure(fig, plot, custom_colors, row=i+1, col=1)\n                \n                elif num_plots <= 4:\n                    # 3-4 plots: 2x2 grid\n                    specs = [\n                        [{\"type\": trace_types[0]}, {\"type\": trace_types[1] if len(trace_types) > 1 else trace_types[0]}],\n                        [{\"type\": trace_types[2] if len(trace_types) > 2 else trace_types[0]}, {\"type\": trace_types[3] if len(trace_types) > 3 else trace_types[0]}]\n                    ]\n                    \n                    fig = make_subplots(\n                        rows=2, cols=2,\n                        subplot_titles=[self._safely_get_attr_or_dict_val(plot, \"title\", f\"Plot {i+1}\") for i, plot in enumerate(plots[:4])],\n                        vertical_spacing=0.15,\n                        horizontal_spacing=0.08,\n                        specs=specs\n                    )\n                    positions = [(1,1), (1,2), (2,1), (2,2)]\n                    for i, plot in enumerate(plots[:4]):\n                        row, col = positions[i]\n                        self._add_traces_to_figure(fig, plot, custom_colors, row=row, col=col)\n                \n                # Update overall layout\n                fig.update_layout(\n                    title=f\"{dashboard_title}{' - ' + dashboard_subtitle if dashboard_subtitle else ''}\",\n                    showlegend=False,\n                    height=min(350 * ((num_plots + 1) // 2), 1200),  # Scale height based on number of plots\n                    margin={\"t\": 50, \"b\": 20, \"l\": 20, \"r\": 20},\n                    paper_bgcolor=\"white\"\n                )\n            \n            # Save plot to a temporary file\n            temp_dir = tempfile.gettempdir()\n            file_name = f\"dashboard_{hash(str(dashboard_data))}.png\"\n            img_path = os.path.join(temp_dir, file_name)\n            \n            print(f\"Generating dashboard image...\")\n            \n            # Write the image to the file\n            fig.write_image(img_path)\n            \n            # Create a base64 version as well\n            img_bytes = fig.to_image(format=\"png\")\n            base64_url = f\"data:image/png;base64,{base64.b64encode(img_bytes).decode('utf-8')}\"\n            \n            # Create the markdown with the text response and embedded image\n            markdown_text = f\"{text_response}\\n\\n![{dashboard_title}]({base64_url})\"\n            \n            print(f\"Successfully created dashboard for: {dashboard_title}\")\n            \n            # Create the message\n            message = Message(\n                text=markdown_text,\n                sender=\"Bot\",\n            )\n            \n            return message\n        except Exception as e:\n            import traceback\n            error_trace = traceback.format_exc()\n            print(f\"Error creating dashboard: {error_trace}\")\n            # Fallback to returning an error with the dashboard data if we can't generate an image\n            return Message(\n                text=f\"Error generating dashboard: {str(e)}\\n\\nTraceback:\\n{error_trace}\\n\\nResponse text:\\n{self._format_text_response(dashboard_data)}\",\n                sender=\"Bot\",\n            )\n    \n    def _add_traces_to_figure(self, fig, plot_data, custom_colors=None, row=None, col=None):\n        \"\"\"Add traces from a plot definition to a figure.\"\"\"\n        plot_type = self._safely_get_attr_or_dict_val(plot_data, \"plot_type\", \"bar\")\n        data_items = self._safely_get_attr_or_dict_val(plot_data, \"data\", [])\n        \n        for i, item in enumerate(data_items):\n            trace_type = self._safely_get_attr_or_dict_val(item, \"type\", plot_type)\n            \n            # Get x and y values\n            x_values = self._safely_get_attr_or_dict_val(item, \"x\", [])\n            y_values = self._safely_get_attr_or_dict_val(item, \"y\", [])\n            \n            # Get labels and values for pie charts\n            labels = self._safely_get_attr_or_dict_val(item, \"labels\", [])\n            values = self._safely_get_attr_or_dict_val(item, \"values\", [])\n            \n            # Prepare marker properties\n            base_marker = self._safely_get_attr_or_dict_val(item, \"marker\", {})\n            \n            # Use custom colors if available\n            if custom_colors and i < len(custom_colors):\n                marker_color = custom_colors[i]\n                if isinstance(base_marker, dict):\n                    base_marker[\"color\"] = marker_color\n                else:\n                    base_marker = {\"color\": marker_color}\n            \n            # Create the trace based on type\n            if trace_type == \"bar\":\n                trace = go.Bar(\n                    x=x_values,\n                    y=y_values,\n                    name=self._safely_get_attr_or_dict_val(item, \"name\", f\"Series {i+1}\"),\n                    marker=base_marker,\n                    orientation=self._safely_get_attr_or_dict_val(item, \"orientation\", \"v\"),\n                )\n            elif trace_type == \"line\":\n                trace = go.Scatter(\n                    x=x_values,\n                    y=y_values,\n                    name=self._safely_get_attr_or_dict_val(item, \"name\", f\"Series {i+1}\"),\n                    mode=self._safely_get_attr_or_dict_val(item, \"mode\", \"lines\"),\n                    marker=base_marker,\n                    line=self._safely_get_attr_or_dict_val(item, \"line\", {}),\n                    fill=self._safely_get_attr_or_dict_val(item, \"fill\"),\n                    fillcolor=self._safely_get_attr_or_dict_val(item, \"fillcolor\"),\n                )\n            elif trace_type == \"area\":\n                trace = go.Scatter(\n                    x=x_values,\n                    y=y_values,\n                    name=self._safely_get_attr_or_dict_val(item, \"name\", f\"Series {i+1}\"),\n                    mode=self._safely_get_attr_or_dict_val(item, \"mode\", \"lines\"),\n                    marker=base_marker,\n                    line=self._safely_get_attr_or_dict_val(item, \"line\", {}),\n                    fill=\"tozeroy\",\n                    fillcolor=self._safely_get_attr_or_dict_val(item, \"fillcolor\", \"rgba(100, 100, 255, 0.3)\"),\n                )\n            elif trace_type == \"scatter\":\n                trace = go.Scatter(\n                    x=x_values,\n                    y=y_values,\n                    name=self._safely_get_attr_or_dict_val(item, \"name\", f\"Series {i+1}\"),\n                    mode=self._safely_get_attr_or_dict_val(item, \"mode\", \"markers\"),\n                    marker=base_marker,\n                )\n            elif trace_type == \"pie\":\n                trace = go.Pie(\n                    labels=labels,\n                    values=values,\n                    name=self._safely_get_attr_or_dict_val(item, \"name\", f\"Series {i+1}\"),\n                    marker=base_marker,\n                )\n            else:\n                continue  # Skip unknown trace types\n            \n            # Add the trace to the figure\n            if row is not None and col is not None:\n                fig.add_trace(trace, row=row, col=col)\n            else:\n                fig.add_trace(trace)"
              },
              "customize_colors": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Customize Colors",
                "dynamic": false,
                "info": "Optional comma-separated colors to use (e.g., 'blue,red,green')",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "customize_colors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "structured_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Structured Data",
                "dynamic": false,
                "info": "The structured data from a StructuredOutput component or CSV agent response",
                "input_types": [
                  "Data",
                  "Message",
                  "dict",
                  "str"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "structured_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PlotlyVisualizerComponent"
        },
        "id": "PlotlyVisualizerComponent-6JNkF",
        "measured": {
          "height": 293,
          "width": 320
        },
        "position": {
          "x": 2920.220025231533,
          "y": 7434.406425232923
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -774.183975582559,
      "y": -3116.7196310131476,
      "zoom": 0.6945121820808351
    }
  },
  "description": "Analysis of a csv report ",
  "endpoint_name": null,
  "folder_id": "85ab20e0-6b2e-477a-894e-164a8e4e52e6",
  "fs_path": null,
  "gradient": null,
  "icon": null,
  "icon_bg_color": null,
  "id": "1bab6f31-82c1-465c-ad61-c72cc11f5194",
  "is_component": false,
  "locked": false,
  "mcp_enabled": true,
  "name": "Data scientist flow",
  "tags": [],
  "updated_at": "2025-05-23T21:15:31+00:00",
  "user_id": "1752bbdd-9926-4869-b737-f02b125c1650",
  "webhook": false
}